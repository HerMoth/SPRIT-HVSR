{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID                                           datapath     site  xcoord   \n",
      "0   0  \\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\HV...  BOM5_23       0  \\\n",
      "1   1  \\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\HV...     BNE4       0   \n",
      "2   2  \\\\isgs-sinkhole.ad.uillinois.edu\\geophysics\\HV...   BOP2_1  352932   \n",
      "\n",
      "    ycoord  elevation   acq_date starttime endtime station       tzone source   \n",
      "0        0          0  7/25/2023     10:18   10:43   RAC84  US/Central   file  \\\n",
      "1        0          0  7/10/2023     22:37   22:59   RAC99         UTC   file   \n",
      "2  4656098        727  7/12/2023     10:41   11:03   RAC84  US/Central    raw   \n",
      "\n",
      "                          trim_dir  \n",
      "0                              NaN  \n",
      "1                              NaN  \n",
      "2  C:\\Users\\riley\\OneDrive\\Desktop  \n",
      "[{'datapath': '\\\\\\\\isgs-sinkhole.ad.uillinois.edu\\\\geophysics\\\\HVSR\\\\BooneCo\\\\BooneCo23\\\\HVSRData\\\\Raw\\\\BOM5_23_AM.RAC84.00.2023.206_2023-07-25_1518-1543.MSEED', 'site': 'BOM5_23', 'xcoord': 0, 'ycoord': 0, 'elevation': 0, 'acq_date': '7/25/2023', 'starttime': '10:18', 'endtime': '10:43', 'station': 'RAC84', 'tzone': 'US/Central', 'source': 'file', 'trim_dir': nan}, {'datapath': '\\\\\\\\isgs-sinkhole.ad.uillinois.edu\\\\geophysics\\\\HVSR\\\\BooneCo\\\\BooneCo23\\\\HVSRData\\\\Raw\\\\BNE_4_AM.RAC84.00.2023.191_2023-07-10_2237-2259.MSEED', 'site': 'BNE4', 'xcoord': 0, 'ycoord': 0, 'elevation': 0, 'acq_date': '7/10/2023', 'starttime': '22:37', 'endtime': '22:59', 'station': 'RAC99', 'tzone': 'UTC', 'source': 'file', 'trim_dir': nan}, {'datapath': '\\\\\\\\isgs-sinkhole.ad.uillinois.edu\\\\geophysics\\\\HVSR\\\\_RawData\\\\data_exports\\\\RAC84\\\\2023-07-31', 'site': 'BOP2_1', 'xcoord': 352932, 'ycoord': 4656098, 'elevation': 727, 'acq_date': '7/12/2023', 'starttime': '10:41', 'endtime': '11:03', 'station': 'RAC84', 'tzone': 'US/Central', 'source': 'raw', 'trim_dir': 'C:\\\\Users\\\\riley\\\\OneDrive\\\\Desktop'}]\n",
      "dict_keys(['net', 'sta', 'loc', 'cha', 'instrument', 'acq_date', 'starttime', 'endtime', 'timezone', 'longitude', 'latitude', 'elevation', 'depth', 'site', 'datapath', 'metapath', 'hvsr_band', 'inv', 'paz'])\n",
      "{'net': 'AM', 'sta': 'RAC84', 'loc': '00', 'cha': ['EHZ', 'EHN', 'EHE'], 'instrument': 'Raspberry Shake', 'acq_date': datetime.date(2023, 7, 25), 'starttime': UTCDateTime(2023, 7, 25, 15, 18), 'endtime': UTCDateTime(2023, 7, 25, 15, 43), 'timezone': 'UTC', 'longitude': 0, 'latitude': 0, 'elevation': 0, 'depth': 0, 'site': 'BOM5_23', 'datapath': '\\\\\\\\isgs-sinkhole.ad.uillinois.edu\\\\geophysics\\\\HVSR\\\\BooneCo\\\\BooneCo23\\\\HVSRData\\\\Raw\\\\BOM5_23_AM.RAC84.00.2023.206_2023-07-25_1518-1543.MSEED', 'metapath': WindowsPath('c:/Users/riley/LocalData/Github/SPRIT-HVSR/sprit/resources/rs3dv7_metadata.inv'), 'hvsr_band': [0.4, 40], 'inv': <obspy.core.inventory.inventory.Inventory object at 0x0000021AD311A530>, 'paz': {'Z': {'sensitivity': 360000000.0, 'gain': 360000000.0, 'poles': [(-1+0j), (-1+0j), (-3.03+0j), (-3.03+0j), (-3.03+0j), (-3.03+0j), (-666.67+0j), (-666.67+0j)], 'zeros': [0j, 0j, 0j, 0j, 0j, 0j]}, 'N': {'sensitivity': 360000000.0, 'gain': 360000000.0, 'poles': [(-1+0j), (-1+0j), (-3.03+0j), (-3.03+0j), (-3.03+0j), (-3.03+0j), (-666.67+0j), (-666.67+0j)], 'zeros': [0j, 0j, 0j, 0j, 0j, 0j]}, 'E': {'sensitivity': 360000000.0, 'gain': 360000000.0, 'poles': [(-1+0j), (-1+0j), (-3.03+0j), (-3.03+0j), (-3.03+0j), (-3.03+0j), (-666.67+0j), (-666.67+0j)], 'zeros': [0j, 0j, 0j, 0j, 0j, 0j]}}}\n",
      "\n",
      "[ERR] Input cannot be converted to pathlib path\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'nan/BOM5_23_AM.RAC84.00.2023.206_2023-07-25_1518-1542.mseed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 141\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[39mreturn\u001b[39;00m stream_dict\n\u001b[0;32m    140\u001b[0m dataPath \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mriley\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mOneDrive - University of Illinois - Urbana\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mCodesandScripts\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mHVSR_Batch_practice.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 141\u001b[0m batch_data_read(input_data\u001b[39m=\u001b[39;49mdataPath, batch_type\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcsv\u001b[39;49m\u001b[39m'\u001b[39;49m, param_col\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, batch_params\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "Cell \u001b[1;32mIn[1], line 82\u001b[0m, in \u001b[0;36mbatch_data_read\u001b[1;34m(input_data, batch_type, param_col, batch_params, verbose, **readcsv_getMeta_fetch_kwargs)\u001b[0m\n\u001b[0;32m     80\u001b[0m fetch_data_kwargs2 \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m param_dict\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m sprit\u001b[39m.\u001b[39mfetch_data\u001b[39m.\u001b[39m\u001b[39m__code__\u001b[39m\u001b[39m.\u001b[39mco_varnames[\u001b[39m0\u001b[39m:\u001b[39m7\u001b[39m]}\n\u001b[0;32m     81\u001b[0m fetch_data_kwargs\u001b[39m.\u001b[39mupdate(fetch_data_kwargs2)\n\u001b[1;32m---> 82\u001b[0m params \u001b[39m=\u001b[39m sprit\u001b[39m.\u001b[39mfetch_data(params\u001b[39m=\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfetch_data_kwargs)\n\u001b[0;32m     83\u001b[0m \u001b[39mprint\u001b[39m(params)\n\u001b[0;32m     85\u001b[0m \u001b[39m#if isinstance(read_params, dict):\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[39m#    stream = obspy.read(file, **read_params)\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[39m#else:\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[39m#    stream = obspy.read(file)\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \n\u001b[0;32m     90\u001b[0m \u001b[39m# Get the network, station, and location codes\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\riley\\LocalData\\Github\\SPRIT-HVSR\\sprit\\sprit.py:959\u001b[0m, in \u001b[0;36mfetch_data\u001b[1;34m(params, inv, source, trim_dir, export_format, detrend, detrend_order, verbose)\u001b[0m\n\u001b[0;32m    957\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m    958\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 959\u001b[0m     dataIN \u001b[39m=\u001b[39m trim_data(stream\u001b[39m=\u001b[39;49mdataIN, params\u001b[39m=\u001b[39;49mparams, export_dir\u001b[39m=\u001b[39;49mtrim_dir, export_format\u001b[39m=\u001b[39;49mexport_format)\n\u001b[0;32m    962\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dataIN[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdata, np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39mmasked_array):\n\u001b[0;32m    963\u001b[0m     dataIN \u001b[39m=\u001b[39m dataIN\u001b[39m.\u001b[39msplit()\n",
      "File \u001b[1;32mc:\\Users\\riley\\LocalData\\Github\\SPRIT-HVSR\\sprit\\sprit.py:1393\u001b[0m, in \u001b[0;36mtrim_data\u001b[1;34m(params, stream, export_dir, export_format, **kwargs)\u001b[0m\n\u001b[0;32m   1390\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1391\u001b[0m         st_trimmed \u001b[39m=\u001b[39m st_trimmed\u001b[39m.\u001b[39msplit()\n\u001b[1;32m-> 1393\u001b[0m     st_trimmed\u001b[39m.\u001b[39;49mwrite(filename\u001b[39m=\u001b[39;49mexportFile)\n\u001b[0;32m   1394\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1395\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\riley\\LocalData\\virtual_envs\\seismic310_venv\\lib\\site-packages\\obspy\\core\\stream.py:1456\u001b[0m, in \u001b[0;36mStream.write\u001b[1;34m(self, filename, format, **kwargs)\u001b[0m\n\u001b[0;32m   1453\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mWriting format \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m is not supported. Supported types: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1454\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg \u001b[39m%\u001b[39m (\u001b[39mformat\u001b[39m,\n\u001b[0;32m   1455\u001b[0m                             \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(ENTRY_POINTS[\u001b[39m'\u001b[39m\u001b[39mwaveform_write\u001b[39m\u001b[39m'\u001b[39m])))\n\u001b[1;32m-> 1456\u001b[0m write_format(\u001b[39mself\u001b[39m, filename, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\riley\\LocalData\\virtual_envs\\seismic310_venv\\lib\\site-packages\\obspy\\io\\mseed\\core.py:829\u001b[0m, in \u001b[0;36m_write_mseed\u001b[1;34m(stream, filename, encoding, reclen, byteorder, sequence_number, flush, verbose, **_kwargs)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[39m# Open filehandler or use an existing file like object.\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(filename, \u001b[39m'\u001b[39m\u001b[39mwrite\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 829\u001b[0m     f \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(filename, \u001b[39m'\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    830\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    831\u001b[0m     f \u001b[39m=\u001b[39m filename\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'nan/BOM5_23_AM.RAC84.00.2023.206_2023-07-25_1518-1542.mseed'"
     ]
    }
   ],
   "source": [
    "import sprit\n",
    "import obspy\n",
    "import pandas as pd\n",
    "\n",
    "def batch_data_read(input_data, batch_type='csv', param_col=None, batch_params=None, verbose=False, **readcsv_getMeta_fetch_kwargs):\n",
    "    \"\"\"Function to read list of files and parameters\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : filepath or list\n",
    "        Filepath to file that can be read using pandas.read_csv()\n",
    "    batch_type : str {'csv', 'list'}\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    stream_dict : dict\n",
    "        Dictionary contiaining unique streams\n",
    "    \"\"\"\n",
    "\n",
    "    # Dictionary to store the stream objects\n",
    "    stream_dict = {}\n",
    "    data_dict = {}\n",
    "    if batch_type == 'csv':\n",
    "        #Read csv\n",
    "        read_csv_kwargs = {k: v for k, v in locals()['readcsv_getMeta_fetch_kwargs'].items() if k in pd.read_csv.__code__.co_varnames}\n",
    "        dataReadInfoDF = pd.read_csv(input_data, **read_csv_kwargs, verbose=verbose)\n",
    "        #***WHAT ABOUT THE NANS? nan ***\n",
    "        \n",
    "        print(dataReadInfoDF)\n",
    "        #First figure out columns\n",
    "        input_params_params = sprit.input_params.__code__.co_varnames\n",
    "        get_metadata_params = sprit.get_metadata.__code__.co_varnames\n",
    "        fetch_data_params = sprit.fetch_data.__code__.co_varnames\n",
    "\n",
    "        param_dict_list = []\n",
    "        if param_col is None: #Not a single parameter column, each col=parameter\n",
    "            for row_ind in range(dataReadInfoDF.shape[0]):\n",
    "                param_dict = {}\n",
    "                for col in dataReadInfoDF.columns:\n",
    "                    if col in input_params_params or col in get_metadata_params or col in fetch_data_params:\n",
    "                        param_dict[col] = dataReadInfoDF.loc[row_ind, col]\n",
    "                param_dict_list.append(param_dict)\n",
    "        else:\n",
    "            for row in dataReadInfoDF[param_col]:\n",
    "                param_dict = {}\n",
    "                splitRow = str(row).split(',')\n",
    "                for item in splitRow:\n",
    "                    param_dict[item.split('=')[0]] = item.split('=')[1]\n",
    "                param_dict_list.append(param_dict)\n",
    "        #input_params(datapath,site,network,station,loc,channels, acq_date,starttime, endtime, tzone, xcoord, ycoord, elevation, depth, instrument, metapath, hvsr_band)\n",
    "        #fetch_data(params, inv, source, trim_dir, export_format, detrend, detrend_order, verbose)\n",
    "        #get_metadata(params, write_path)\n",
    "\n",
    "        #file_setup_kwargs = {k: v for k, v in locals()['keyword_parameters'].items() if k in w4h.file_setup.__code__.co_varnames}\n",
    "        print(param_dict_list)\n",
    "    elif batch_type == 'filelist':\n",
    "        # Read and process each MiniSEED file\n",
    "        for i, file in enumerate(input_data):\n",
    "            if batch_params is None:\n",
    "                pass\n",
    "            elif isinstance(batch_params, list):\n",
    "                read_params = batch_params[i]\n",
    "            elif isinstance(batch_params, dict):\n",
    "                pass\n",
    "                #Update this eventually\n",
    "\n",
    "    hvsr_metaDict = {}\n",
    "    for param_dict in param_dict_list:\n",
    "        # Read the data file into a Stream object\n",
    "        input_params_kwargs = {k: v for k, v in locals()['readcsv_getMeta_fetch_kwargs'].items() if k in sprit.input_params.__code__.co_varnames}\n",
    "        input_params_kwargs2 = {k: v for k, v in param_dict.items() if k in sprit.input_params.__code__.co_varnames}\n",
    "        input_params_kwargs.update(input_params_kwargs2)\n",
    "        params = sprit.input_params(**input_params_kwargs)\n",
    "\n",
    "        get_metadata_kwargs = {k: v for k, v in locals()['readcsv_getMeta_fetch_kwargs'].items() if k in sprit.get_metadata.__code__.co_varnames}\n",
    "        get_metadata_kwargs2 = {k: v for k, v in param_dict.items() if k in sprit.get_metadata.__code__.co_varnames}\n",
    "        get_metadata_kwargs.update(get_metadata_kwargs2)\n",
    "        params = sprit.get_metadata(params=params, **get_metadata_kwargs)\n",
    "\n",
    "        print(params.keys())\n",
    "        fetch_data_kwargs = {k: v for k, v in locals()['readcsv_getMeta_fetch_kwargs'].items() if k in sprit.fetch_data.__code__.co_varnames}\n",
    "        fetch_data_kwargs2 = {k: v for k, v in param_dict.items() if k in sprit.fetch_data.__code__.co_varnames[0:7]}\n",
    "        fetch_data_kwargs.update(fetch_data_kwargs2)\n",
    "        params = sprit.fetch_data(params=params, **fetch_data_kwargs)\n",
    "        print(params)\n",
    "\n",
    "        #if isinstance(read_params, dict):\n",
    "        #    stream = obspy.read(file, **read_params)\n",
    "        #else:\n",
    "        #    stream = obspy.read(file)\n",
    "\n",
    "        # Get the network, station, and location codes\n",
    "        network = stream[0].stats.network\n",
    "        station = stream[0].stats.station\n",
    "        location = stream[0].stats.location\n",
    "        \n",
    "        # Create a unique identifier for the network-station-location combination\n",
    "        stream_id = f\"{network}.{station}.{location}\"\n",
    "\n",
    "        # Check if the stream has a single trace\n",
    "        if len(stream) == 1:\n",
    "\n",
    "            # Check if the stream ID exists in the dictionary\n",
    "            if stream_id in stream_dict:\n",
    "                if stream[0].stats.channel == 'Z':\n",
    "                    stream_dict[stream_id][0] = stream[0]\n",
    "                elif stream[0].stats.channel == 'E':\n",
    "                    stream_dict[stream_id][1] = stream[0]\n",
    "                elif stream[0].stats.channel == 'N':\n",
    "                    stream_dict[stream_id][2] = stream[0]\n",
    "            else:\n",
    "                # Create a new stream object with the first trace and assign Z, E, and N channels\n",
    "                new_stream = obspy.Stream(traces=[None, None, None])\n",
    "                if stream[0].stats.channel == 'Z':\n",
    "                    new_stream[0] = stream[0]\n",
    "                elif stream[0].stats.channel == 'E':\n",
    "                    new_stream[1] = stream[0]\n",
    "                elif stream[0].stats.channel == 'N':\n",
    "                    new_stream[2] = stream[0]\n",
    "                # Assign network, station, location, etc. to the new_stream as required\n",
    "                stream_dict[stream_id] = new_stream\n",
    "        else:\n",
    "            # Check if the stream has required channels and add it directly to stream_dict\n",
    "            if has_required_channels(stream):\n",
    "                stream_dict[stream_id] = stream\n",
    "\n",
    "    # Validate the channels for each stream in stream_dict\n",
    "    for stream_id, stream in stream_dict.items():\n",
    "        if not has_required_channels(stream):\n",
    "            if verbose:\n",
    "                print(f\"Stream {stream_id} does not have all required channels, removing from analysis.\")\n",
    "            del stream_dict[stream_id]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Streams:\\n\")\n",
    "        print(stream_dict.keys())\n",
    "        #for k in stream_dict.keys():\n",
    "        #    print(k)\n",
    "\n",
    "    return stream_dict\n",
    "\n",
    "dataPath = r\"C:\\Users\\riley\\OneDrive - University of Illinois - Urbana\\CodesandScripts\\HVSR_Batch_practice.csv\"\n",
    "batch_data_read(input_data=dataPath, batch_type='csv', param_col=None, batch_params=None, verbose=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismic310_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
