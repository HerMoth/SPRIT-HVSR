{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\LocalData\\virtual_envs\\seismic310_venv\\lib\\site-packages\\obspy\\core\\inventory\\network.py:251: UserWarning: Found more than one matching response. Returning first.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['BOM5_23', 'HVSR Site_0', 'BOP2_1'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sprit\n",
    "import obspy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "def batch_data_read(input_data, batch_type='csv', param_col=None, batch_params=None, verbose=False, **readcsv_getMeta_fetch_kwargs):\n",
    "    \"\"\"Function to read data in data as a batch of multiple data files\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : filepath or list\n",
    "        Input data information for how to read in data as batch\n",
    "    batch_type : str, optional\n",
    "        Type of batch read, only 'csv' and 'filelist' accepted. If 'csv', will read data from a file read in using pandas.read_csv(), by default 'csv'\n",
    "    param_col : None or str, optional\n",
    "        Name of parameter column from batch information file. Only used if a batch_type='csv' and single parameter column is used, rather than one column per parameter (for single parameter column, parameters are formatted with = between keys/values and , between item pairs), by default None\n",
    "    batch_params : dict or list, optional\n",
    "        Dictionary containing keyword arguments for pandas.read_csv(), sprit.input_params(), sprit.get_metadata(), and sprit.fetch_data(). Only used iwth batch_type='filelist. If dict, will use same parameters for all files. If list of dicts, needs to be same length as input_data, by default None\n",
    "    verbose : bool, optional\n",
    "        Whether to print information to terminal during batch read, by default False\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary with each item representing a different file read in, and which consists of its own parameter dictionary to be used by the rest of the processing steps\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    IndexError\n",
    "        _description_\n",
    "    \"\"\"\n",
    "\n",
    "    # Dictionary to store the stream objects\n",
    "    stream_dict = {}\n",
    "    data_dict = {}\n",
    "    if batch_type == 'csv':\n",
    "        #Read csv\n",
    "        read_csv_kwargs = {k: v for k, v in locals()['readcsv_getMeta_fetch_kwargs'].items() if k in pd.read_csv.__code__.co_varnames}\n",
    "        dataReadInfoDF = pd.read_csv(input_data, **read_csv_kwargs, verbose=verbose)\n",
    "        #dataReadInfoDF = dataReadInfoDF.replace(np.nan, None)\n",
    "\n",
    "        default_dict = {'site':'HVSR Site',\n",
    "                    'network':'AM', \n",
    "                    'station':'RAC84', \n",
    "                    'loc':'00', \n",
    "                    'channels':['EHZ', 'EHN', 'EHE'],\n",
    "                    'acq_date':str(datetime.datetime.now().date()),\n",
    "                    'starttime' : '00:00:00.00',\n",
    "                    'endtime' : '23:59:59.999',\n",
    "                    'tzone' : 'UTC',\n",
    "                    'xcoord' : -88.2290526,\n",
    "                    'ycoord' :  40.1012122,\n",
    "                    'elevation' : 755,\n",
    "                    'input_crs':'EPSG:4326',#4269 is NAD83, defautling to WGS\n",
    "                    'output_crs':'EPSG:4326',\n",
    "                    'elev_unit' : 'feet',\n",
    "                    'depth' : 0,\n",
    "                    'instrument' : 'Raspberry Shake',\n",
    "                    'metapath' : '',\n",
    "                    'hvsr_band' : [0.4, 40],\n",
    "                    'write_path':'',\n",
    "                    'source':'file', \n",
    "                    'export_format':'mseed', \n",
    "                    'detrend':'spline', \n",
    "                    'detrend_order':2, \n",
    "                    'verbose':False}\n",
    "\n",
    "        if verbose:\n",
    "            print(dataReadInfoDF)\n",
    "        #First figure out columns\n",
    "        input_params_params = sprit.input_params.__code__.co_varnames\n",
    "        get_metadata_params = sprit.get_metadata.__code__.co_varnames\n",
    "        fetch_data_params = sprit.fetch_data.__code__.co_varnames\n",
    "\n",
    "        param_dict_list = []\n",
    "        if param_col is None: #Not a single parameter column, each col=parameter\n",
    "            for row_ind in range(dataReadInfoDF.shape[0]):\n",
    "                param_dict = {}\n",
    "                for col in dataReadInfoDF.columns:\n",
    "                    if col in input_params_params or col in get_metadata_params or col in fetch_data_params:\n",
    "                        currParam = dataReadInfoDF.loc[row_ind, col]\n",
    "                        if pd.isna(currParam) or currParam == 'nan':\n",
    "                            if col in default_dict.keys():\n",
    "                                param_dict[col] = default_dict[col] #Get default value\n",
    "                                if verbose:\n",
    "                                    print('Replacing blank value for {} from file with default value {}'.format(col, default_dict[col]))\n",
    "                            else:\n",
    "                                param_dict[col] = None\n",
    "                        else:\n",
    "                            param_dict[col] = dataReadInfoDF.loc[row_ind, col]\n",
    "                param_dict_list.append(param_dict)\n",
    "        else:\n",
    "            if param_col not in dataReadInfoDF.columns:\n",
    "                raise IndexError('{} is not a column in {} (columns are: {})'.format(param_col, input_data, dataReadInfoDF.columns))\n",
    "            for row in dataReadInfoDF[param_col]:\n",
    "                param_dict = {}\n",
    "                splitRow = str(row).split(',')\n",
    "                for item in splitRow:\n",
    "                    param_dict[item.split('=')[0]] = item.split('=')[1]\n",
    "                param_dict_list.append(param_dict)\n",
    "        #input_params(datapath,site,network,station,loc,channels, acq_date,starttime, endtime, tzone, xcoord, ycoord, elevation, depth, instrument, metapath, hvsr_band)\n",
    "        #fetch_data(params, inv, source, trim_dir, export_format, detrend, detrend_order, verbose)\n",
    "        #get_metadata(params, write_path)\n",
    "\n",
    "    elif batch_type == 'filelist':\n",
    "        # Read and process each MiniSEED file\n",
    "        for i, file in enumerate(input_data):\n",
    "            if batch_params is None:\n",
    "                pass\n",
    "            elif isinstance(batch_params, list):\n",
    "                read_params = batch_params[i]\n",
    "            elif isinstance(batch_params, dict):\n",
    "                pass\n",
    "                #Update this eventually\n",
    "\n",
    "    hvsr_metaDict = {}\n",
    "    zfillDigs = len(str(len(param_dict_list))) #Get number of digits of length of param_dict_list\n",
    "    i=0\n",
    "    for param_dict in param_dict_list:\n",
    "        # Read the data file into a Stream object\n",
    "        input_params_kwargs = {k: v for k, v in locals()['readcsv_getMeta_fetch_kwargs'].items() if k in sprit.input_params.__code__.co_varnames}\n",
    "        input_params_kwargs2 = {k: v for k, v in param_dict.items() if k in sprit.input_params.__code__.co_varnames}\n",
    "        input_params_kwargs.update(input_params_kwargs2)\n",
    "        params = sprit.input_params(**input_params_kwargs)\n",
    "\n",
    "        get_metadata_kwargs = {k: v for k, v in locals()['readcsv_getMeta_fetch_kwargs'].items() if k in sprit.get_metadata.__code__.co_varnames}\n",
    "        get_metadata_kwargs2 = {k: v for k, v in param_dict.items() if k in sprit.get_metadata.__code__.co_varnames}\n",
    "        get_metadata_kwargs.update(get_metadata_kwargs2)\n",
    "        params = sprit.get_metadata(params=params, **get_metadata_kwargs)\n",
    "\n",
    "        fetch_data_kwargs = {k: v for k, v in locals()['readcsv_getMeta_fetch_kwargs'].items() if k in sprit.fetch_data.__code__.co_varnames}\n",
    "        fetch_data_kwargs2 = {k: v for k, v in param_dict.items() if k in sprit.fetch_data.__code__.co_varnames[0:7]}\n",
    "        fetch_data_kwargs.update(fetch_data_kwargs2)\n",
    "        params = sprit.fetch_data(params=params, **fetch_data_kwargs)\n",
    "\n",
    "        if params['site'] == default_dict['site']: #If site was not designated\n",
    "            params['site'] = \"{}_{}\".format(params['site'], str(i).zfill(zfillDigs))\n",
    "            i+=1\n",
    "        hvsr_metaDict[params['site']] = params\n",
    "    \n",
    "    return hvsr_metaDict\n",
    "\n",
    "dataPath = r\"C:\\Users\\riley\\OneDrive - University of Illinois - Urbana\\CodesandScripts\\HVSR_Batch_practice.csv\"\n",
    "hvsr_data_batch = batch_data_read(input_data=dataPath, batch_type='csv', param_col=None, batch_params=None, verbose=False)\n",
    "hvsr_data_batch.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismic310_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
