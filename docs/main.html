<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>sprit API documentation</title>
<meta name="description" content="This module analysis ambient seismic data using the Horizontal to Vertical Spectral Ratio (HVSR) technique" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Package <code>sprit</code></h1>
</header>
<section id="section-intro">
<p>This module analysis ambient seismic data using the Horizontal to Vertical Spectral Ratio (HVSR) technique</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">#__init__.py
&#34;&#34;&#34;
This module analysis ambient seismic data using the Horizontal to Vertical Spectral Ratio (HVSR) technique
&#34;&#34;&#34;

from sprit.sprit import(
    check_mark,
    get_char,
    time_it,
    message,
    error,
    warning,
    info,
    checkifpath,
    input_params,
    update_shake_metadata,
    setup_colab,
    gui,
    get_metadata,
    fetch_data,
    trim_data,
    generate_ppsds,
    process_hvsr,
    plot_stream,
    plot_specgram_stream,
    hvplot,
    plot_hvsr,
    plot_specgram_hvsr,
    select_windows,
    remove_noise,
    show_removed_windows,
    check_peaks,
    print_report
)

__all__ =(&#39;sprit&#39;,
    &#39;check_mark&#39;,
    &#39;get_char&#39;,
    &#39;time_it&#39;,
    &#39;message&#39;,
    &#39;error&#39;,
    &#39;warning&#39;,
    &#39;info&#39;,
    &#39;checkifpath&#39;,
    &#39;input_params&#39;,
    &#39;update_shake_metadata&#39;,
    &#39;setup_colab&#39;,
    &#39;gui&#39;,
    &#39;get_metadata&#39;,
    &#39;fetch_data&#39;,
    &#39;trim_data&#39;,
    &#39;generate_ppsds&#39;,
    &#39;process_hvsr&#39;,
    &#39;plot_stream&#39;,
    &#39;plot_specgram_stream&#39;,
    &#39;hvplot&#39;,
    &#39;plot_hvsr&#39;,
    &#39;plot_specgram_hvsr&#39;,
    &#39;select_windows&#39;,
    &#39;remove_noise&#39;,
    &#39;show_removed_windows&#39;,
    &#39;check_peaks&#39;,
    &#39;print_report&#39;
)

__author__ = &#39;Riley Balikian&#39;</code></pre>
</details>
</section>
<section>
<h2 class="section-title" id="header-submodules">Sub-modules</h2>
<dl>
<dt><code class="name"><a title="sprit.sprit" href="sprit.html">sprit.sprit</a></code></dt>
<dd>
<div class="desc"><p>This module contains all the functions needed to run the HVSR analysis</p></div>
</dd>
<dt><code class="name"><a title="sprit.sprit_gui" href="sprit_gui.html">sprit.sprit_gui</a></code></dt>
<dd>
<div class="desc"><p>This script contains all the functions, classes, etc. to create a tkinter app for graphical user interface â€¦</p></div>
</dd>
</dl>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="sprit.check_mark"><code class="name flex">
<span>def <span class="ident">check_mark</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>The default Windows terminal is not able to display the check mark character correctly.
This function returns another displayable character if platform is Windows</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_mark():
    &#34;&#34;&#34;The default Windows terminal is not able to display the check mark character correctly.
       This function returns another displayable character if platform is Windows&#34;&#34;&#34;
    #This does not seem to be a problem for my system at least, so am not using it currently
    check = get_char(u&#39;\u2714&#39;)
    #if sys.platform == &#39;win32&#39;:
    #    check = get_char(u&#39;\u039E&#39;)
    return check</code></pre>
</details>
</dd>
<dt id="sprit.check_peaks"><code class="name flex">
<span>def <span class="ident">check_peaks</span></span>(<span>hvsr_dict, hvsr_band=[0.4, 40], peak_water_level=1.8)</span>
</code></dt>
<dd>
<div class="desc"><p>Function to run tests on HVSR peaks to find best one and see if it passes quality checks</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>hvsr_dict</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dictionary containing all the calculated information about the HVSR data (i.e., hvsr_out returned from process_hvsr)</dd>
<dt>hvsr_band
: tuple or list, default=[0.4, 40]</dt>
<dt>2-item tuple or list with lower and upper limit of frequencies to analyze</dt>
<dt><strong><code>peak_water_level</code></strong> :&ensp;<code>float</code>, default=<code>1.8</code></dt>
<dd>Value of peak water level</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>hvsr_dict
: dict</code></dt>
<dd>Dictionary containing previous input data, plus information about Peak tests</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_peaks(hvsr_dict, hvsr_band=[0.4, 40], peak_water_level=1.8):
    &#34;&#34;&#34;Function to run tests on HVSR peaks to find best one and see if it passes quality checks

        Parameters
        ----------
        hvsr_dict : dict
            Dictionary containing all the calculated information about the HVSR data (i.e., hvsr_out returned from process_hvsr)
        hvsr_band  : tuple or list, default=[0.4, 40]
            2-item tuple or list with lower and upper limit of frequencies to analyze
        peak_water_level: float, default=1.8
            Value of peak water level

        Returns
        -------
        hvsr_dict   : dict
            Dictionary containing previous input data, plus information about Peak tests
    &#34;&#34;&#34;

    if not hvsr_band:
        hvsr_band = [0.4,40]
    hvsr_dict[&#39;hvsr_band&#39;] = hvsr_band

    anyK = list(hvsr_dict[&#39;x_freqs&#39;].keys())[0]
    x = hvsr_dict[&#39;x_freqs&#39;][anyK]
    y = hvsr_dict[&#39;hvsr_curve&#39;]
    index_list = hvsr_dict[&#39;hvsr_peak_indices&#39;]
    peak_water_level  = hvsr_dict[&#39;peak_water_level&#39;]
    hvsrp = hvsr_dict[&#39;hvsrp&#39;]
    peak_water_level_p  = hvsr_dict[&#39;peak_water_level_p&#39;]
    hvsrm = hvsr_dict[&#39;hvsrm&#39;]
    hvsrPeaks = hvsr_dict[&#39;ind_hvsr_peak_indices&#39;]
    hvsr_log_std = hvsr_dict[&#39;hvsr_log_std&#39;]

    #Do for hvsr
    peak = __init_peaks(x, y, index_list, hvsr_band, peak_water_level)

    peak = __check_curve_reliability(hvsr_dict, peak)
    peak = __check_clarity(x, y, peak, do_rank=True)

    #Do for hvsrp
    # Find  the relative extrema of hvsrp (hvsr + 1 standard deviation)
    if not np.isnan(np.sum(hvsrp)):
        index_p = __find_peaks(hvsrp)
    else:
        index_p = list()

    peakp = __init_peaks(x, hvsrp, index_p, hvsr_band, peak_water_level_p)
    peakp = __check_clarity(x, hvsrp, peakp, do_rank=True)

    #Do for hvsrm
    # Find  the relative extrema of hvsrm (hvsr - 1 standard deviation)
    if not np.isnan(np.sum(hvsrm)):
        index_m = __find_peaks(hvsrm)
    else:
        index_m = list()

    peak_water_level_m  = hvsr_dict[&#39;peak_water_level_m&#39;]

    peakm = __init_peaks(x, hvsrm, index_m, hvsr_band, peak_water_level_m)
    peakm = __check_clarity(x, hvsrm, peakm, do_rank=True)

    stdf = __get_stdf(x, index_list, hvsrPeaks)

    peak = __check_freq_stability(peak, peakm, peakp)
    peak = __check_stability(stdf, peak, hvsr_log_std, rank=True)

    hvsr_dict[&#39;Peak Report&#39;] = peak

    #Iterate through peaks and 
    #   Get the best peak based on the peak score
    #   Calculate whether each peak passes enough tests
    curveTests = [&#39;Window Length Freq.&#39;,&#39;Significant Cycles&#39;, &#39;Low Curve StDev. over time&#39;]
    peakTests = [&#39;Peak Freq. Clarity Below&#39;, &#39;Peak Freq. Clarity Above&#39;, &#39;Peak Amp. Clarity&#39;, &#39;Freq. Stability&#39;, &#39;Peak Stability (freq. std)&#39;, &#39;Peak Stability (amp. std)&#39;]
    bestPeakScore = 0
    for p in hvsr_dict[&#39;Peak Report&#39;]:
        #Get best peak
        if p[&#39;Score&#39;] &gt; bestPeakScore:
            bestPeakScore = p[&#39;Score&#39;]
            bestPeak = p

        #Calculate if peak passes criteria
        cTestsPass = 0
        pTestsPass = 0
        for testName in p[&#39;Pass List&#39;].keys():
            if testName in curveTests:
                if p[&#39;Pass List&#39;][testName]:
                    cTestsPass += 1
            elif testName in peakTests:
                if p[&#39;Pass List&#39;][testName]:
                    pTestsPass += 1

        if cTestsPass == 3 and pTestsPass &gt;= 5:
            p[&#39;Peak Passes&#39;] = True
        else:
            p[&#39;Peak Passes&#39;] = False
        
    #Designate best peak in output dict
    if len(hvsr_dict[&#39;Peak Report&#39;]) == 0:
        bestPeak={}
        print(&#39;No Best Peak identified&#39;)

    hvsr_dict[&#39;Best Peak&#39;] = bestPeak
    return hvsr_dict</code></pre>
</details>
</dd>
<dt id="sprit.checkifpath"><code class="name flex">
<span>def <span class="ident">checkifpath</span></span>(<span>filepath)</span>
</code></dt>
<dd>
<div class="desc"><p>Support function to check if a filepath is a pathlib.Path object and tries to convert if not</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code> or <code>pathlib.Path,</code> or <code>anything</code></dt>
<dd>Filepath to check. If not a valid filepath, will not convert and raises error</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>pathlib.Path</code></dt>
<dd>pathlib.Path of filepath</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def checkifpath(filepath):
    &#34;&#34;&#34;Support function to check if a filepath is a pathlib.Path object and tries to convert if not

    Parameters
    ----------
    filepath : str or pathlib.Path, or anything
        Filepath to check. If not a valid filepath, will not convert and raises error

    Returns
    -------
    filepath : pathlib.Path
        pathlib.Path of filepath
    &#34;&#34;&#34;

    # checks if the variable is any instance of pathlib
    if isinstance(filepath, pathlib.PurePath):
        pass
    else:
        try:
            filepath = pathlib.Path(filepath)
            #print(&#39;Converted string to pathlib path&#39;) #Assume a string was input rather than pathlib object
        except:
            error(&#39;Input cannot be converted to pathlib path&#39;, 0)
    return filepath</code></pre>
</details>
</dd>
<dt id="sprit.error"><code class="name flex">
<span>def <span class="ident">error</span></span>(<span>err_message, code)</span>
</code></dt>
<dd>
<div class="desc"><p>Prints an error message</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def error(err_message, code):
    &#34;&#34;&#34;Prints an error message&#34;&#34;&#34;
    print(&#34;\n[ERR] %s\n&#34; % err_message, flush=True)
    return code</code></pre>
</details>
</dd>
<dt id="sprit.fetch_data"><code class="name flex">
<span>def <span class="ident">fetch_data</span></span>(<span>params, inv=None, source='raw', trim_dir=None, export_format='mseed', detrend='spline', detrend_order=2)</span>
</code></dt>
<dd>
<div class="desc"><p>Fetch ambient seismic data from a source to read into obspy stream</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt>params
: dict</dt>
<dt>Dictionary containing all the necessary params to get data.</dt>
<dt>Parameters defined using input_params() function.</dt>
<dt>inv
: obspy inventory object, default=None</dt>
<dt>Obspy inventory object containing metadata for instrument that collected data to be fetched. By default, the inventory object is read from params['inv'], but this can be manually specified here too.</dt>
<dt _dir_="'dir'," _file_="'file'" _raw_="'raw',">source
: str,</dt>
<dt>String indicating where/how data file was created. For example, if raw data, will need to find correct channels.</dt>
<dt>'raw' finds raspberry shake data, from raw output copied using scp directly from Raspberry Shake, either in folder or subfolders;</dt>
<dt>'dir' is used if the day's 3 component files (currently Raspberry Shake supported only) are all 3 contained in a directory by themselves.</dt>
<dt>'file' is used if the datapath specified in input_params() is the direct filepath to a single file to be read directly into an obspy stream.</dt>
<dt><strong><code>trim_dir</code></strong> :&ensp;<code>None</code> or <code>str</code> or <code>pathlib obj</code>, default=<code>None</code></dt>
<dd>If None (or False), data is not trimmed in this function.
Otherwise, this is the directory to save trimmed and exported data.</dd>
<dt><strong><code>export_format</code></strong> :&ensp;<code>str='mseed'</code></dt>
<dd>If trim_dir is not False, this is the format in which to save the data</dd>
<dt><strong><code>detrend</code></strong> :&ensp;<code>str</code> or <code>bool</code>, default=<code>'spline'</code></dt>
<dd>If False, data is not detrended.
Otherwise, this should be a string accepted by the type parameter of the obspy.core.trace.Trace.detrend method: <a href="https://docs.obspy.org/packages/autogen/obspy.core.trace.Trace.detrend.html">https://docs.obspy.org/packages/autogen/obspy.core.trace.Trace.detrend.html</a></dd>
<dt><strong><code>detrend_order</code></strong> :&ensp;<code>int</code>, default=<code>2</code></dt>
<dd>If detrend parameter is 'spline' or 'polynomial', this is passed directly to the order parameter of obspy.core.trace.Trace.detrend method.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>dataIN</code></strong> :&ensp;<code>obspy stream</code></dt>
<dd>Obspy data stream with 3 traces: Z (vertical), N (North-south), and E (East-west)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fetch_data(params, inv=None, source=&#39;raw&#39;, trim_dir=None, export_format=&#39;mseed&#39;, detrend=&#39;spline&#39;, detrend_order=2):
    &#34;&#34;&#34;Fetch ambient seismic data from a source to read into obspy stream
        
        Parameters
        ----------
        params  : dict
            Dictionary containing all the necessary params to get data.
                Parameters defined using input_params() function.
        inv     : obspy inventory object, default=None
            Obspy inventory object containing metadata for instrument that collected data to be fetched. By default, the inventory object is read from params[&#39;inv&#39;], but this can be manually specified here too.
        source  : str, {&#39;raw&#39;, &#39;dir&#39;, &#39;file&#39;}
            String indicating where/how data file was created. For example, if raw data, will need to find correct channels.
                &#39;raw&#39; finds raspberry shake data, from raw output copied using scp directly from Raspberry Shake, either in folder or subfolders; 
                &#39;dir&#39; is used if the day&#39;s 3 component files (currently Raspberry Shake supported only) are all 3 contained in a directory by themselves.
                &#39;file&#39; is used if the datapath specified in input_params() is the direct filepath to a single file to be read directly into an obspy stream.
        trim_dir : None or str or pathlib obj, default=None
            If None (or False), data is not trimmed in this function.
            Otherwise, this is the directory to save trimmed and exported data.
        export_format: str=&#39;mseed&#39;
            If trim_dir is not False, this is the format in which to save the data
        detrend : str or bool, default=&#39;spline&#39;
            If False, data is not detrended.
            Otherwise, this should be a string accepted by the type parameter of the obspy.core.trace.Trace.detrend method: https://docs.obspy.org/packages/autogen/obspy.core.trace.Trace.detrend.html
        detrend_order : int, default=2
            If detrend parameter is &#39;spline&#39; or &#39;polynomial&#39;, this is passed directly to the order parameter of obspy.core.trace.Trace.detrend method.
        
        Returns
        -------
        dataIN : obspy stream
            Obspy data stream with 3 traces: Z (vertical), N (North-south), and E (East-west)
        
        &#34;&#34;&#34;
    datapath = params[&#39;dataPath&#39;]
    if inv is None:
        inv = params[&#39;inv&#39;], 
    date=params[&#39;acq_date&#39;]
    datapath = checkifpath(datapath)
    inst = params[&#39;instrument&#39;]

    #Need to put dates and times in right formats first
    if type(date) is datetime.datetime:
        doy = date.timetuple().tm_yday
        year = date.year
    elif type(date) is datetime.date:
        date = datetime.datetime.combine(date, datetime.time(hour=0, minute=0, second=0))
        doy = date.timetuple().tm_yday
        year = date.year
    elif type(date) is tuple:
        if date[0]&gt;366:
            error(&#39;First item in date tuple must be day of year (0-366)&#39;, 0)
        elif date[1] &gt; datetime.datetime.now().year:
            error(&#39;Second item in date tuple should be year, but given item is in the future&#39;, 0)
        else:
            doy = date[0]
            year = date[1]
    elif type(date) is str:
        if &#39;/&#39; in date:
            dateSplit = date.split(&#39;/&#39;)            
        elif &#39;-&#39; in date:
            dateSplit = date.split(&#39;-&#39;)
        else:
            dateSplit = date

        if int(dateSplit[0]) &gt; 31:
            date = datetime.datetime(int(dateSplit[0]), int(dateSplit[1]), int(dateSplit[2]))
            doy = date.timetuple().tm_yday
            year = date.year
        elif int(dateSplit[0])&lt;=12 and int(dateSplit[2]) &gt; 31:
            info(&#34;Preferred date format is &#39;yyyy-mm-dd&#39; or &#39;yyyy/mm/dd&#39;. Will attempt to parse date.&#34;)
            date = datetime.datetime(int(dateSplit[2]), int(dateSplit[0]), int(dateSplit[1]))
            doy = date.timetuple().tm_yday
            year = date.year
        else:
            info(&#34;Preferred date format is &#39;yyyy-mm-dd&#39; or &#39;yyyy/mm/dd&#39;. Cannot parse date.&#34;)
    elif type(date) is int:
        doy = date
        year = datetime.datetime.today().year
    else: #FOR NOW, need to update
        date = datetime.datetime.now()
        doy = date.timetuple().tm_yday
        year = date.year
        print(&#34;Did not recognize date, using year {} and day {}&#34;.format(year, doy))

    #Select which instrument we are reading from (requires different processes for each instrument)
    raspShakeInstNameList = [&#39;raspberry shake&#39;, &#39;shake&#39;, &#39;raspberry&#39;, &#39;rs&#39;, &#39;rs3d&#39;, &#39;rasp. shake&#39;, &#39;raspshake&#39;]
    if source==&#39;raw&#39;:
        if inst.lower() in raspShakeInstNameList:
            rawDataIN = __read_RS_data(datapath, source, year, doy, inv, params)
    elif source==&#39;dir&#39;:
        if inst.lower() in raspShakeInstNameList:
            rawDataIN = __read_RS_data(datapath, source, year, doy, inv, params)
    elif source==&#39;file&#39;:
        rawDataIN = obspy.read(datapath)#, starttime=obspy.core.UTCDateTime(params[&#39;starttime&#39;]), endttime=obspy.core.UTCDateTime(params[&#39;endtime&#39;]), nearest_sample =True)
        rawDataIN.attach_response(inv)

    if rawDataIN is None:
        return
    elif isinstance(rawDataIN, obspy.core.stream.Stream):
        #Make sure z component is first
        if &#39;Z&#39; in rawDataIN[0].stats[&#39;channel&#39;]:#).split(&#39;.&#39;)[3]:#[12:15]:
            dataIN = rawDataIN
        else:
            dataIN = rawDataIN.sort([&#39;channel&#39;], reverse=True) #z, n, e order
    else:
        dataIN = []
        for i, st in enumerate(rawDataIN):
            if &#39;Z&#39; in st[0].stats[&#39;channel&#39;]:#).split(&#39;.&#39;)[3]:#[12:15]:
                dataIN.append(rawDataIN[i])
            else:
                dataIN.append(rawDataIN[i].sort([&#39;channel&#39;], reverse=True)) #z, n, e order            
        
    if not trim_dir:
        pass
    else:
        dataIN = trim_data(stream=dataIN, params=params, export_dir=trim_dir, export_format=export_format)

    if detrend==False:
        pass
    elif detrend==True:
        #By default, do a spline removal
        for tr in dataIN:
            tr.detrend(type=&#39;spline&#39;, order=detrend_order, dspline=1000)        
    else:
        if detrend==&#39;simple&#39;:
            for tr in dataIN:
                tr.detrend(type=detrend)
        if detrend==&#39;linear&#39;:
            for tr in dataIN:
                tr.detrend(type=detrend)
        if detrend==&#39;constant&#39; or detrend==&#39;demean&#39;:
            for tr in dataIN:
                tr.detrend(type=detrend)                
        if detrend==&#39;polynomial&#39;:
            for tr in dataIN:
                tr.detrend(type=detrend, order=detrend_order)   
        if detrend==&#39;spline&#39;:
            for tr in dataIN:
                tr.detrend(type=detrend, order=detrend_order, dspline=1000)       
    
    params[&#39;stream&#39;] = dataIN

    return params</code></pre>
</details>
</dd>
<dt id="sprit.generate_ppsds"><code class="name flex">
<span>def <span class="ident">generate_ppsds</span></span>(<span>params, remove_outliers=True, outlier_std=3, verbose=False, **ppsd_kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Generates PPSDs for each channel</p>
<p>Channels need to be in Z, N, E order
Info on PPSD creation here: <a href="https://docs.obspy.org/packages/autogen/obspy.signal.spectral_estimation.PPSD.html">https://docs.obspy.org/packages/autogen/obspy.signal.spectral_estimation.PPSD.html</a></p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>params</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dictionary containing all the parameters and other data of interest (stream and paz, for example)</dd>
<dt><strong><code>remove_outliers</code></strong> :&ensp;<code>bool</code>, default=<code>True</code></dt>
<dd>Whether to remove outlier h/v curves. This is recommended, particularly if remove_noise() has been used.</dd>
<dt><strong><code>outlier_std</code></strong> :&ensp;<code> float</code>, default=<code>3</code></dt>
<dd>The standard deviation value to use as a threshold for determining whether a curve is an outlier.
This averages over the entire curve so that curves with very abberant data (often occurs when using the remove_noise() method), can be identified.</dd>
<dt><strong><code>**kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dictionary with keyword arguments that are passed directly to obspy.signal.PPSD.
If the following keywords are not specified, their defaults are amended in this function from the obspy defaults for its PPSD function. Specifically:
- ppsd_length defaults to 60 (seconds) here instead of 3600
- skip_on_gaps defaults to True instead of False
- period_step_octaves defaults to 0.03125 instead of 0.125</dd>
</dl>
<h2 id="returns">Returns</h2>
<pre><code>ppsds   :   dict
    Dictionary containing entries with ppsds for each channel
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_ppsds(params, remove_outliers=True, outlier_std=3, verbose=False, **ppsd_kwargs):
    &#34;&#34;&#34;Generates PPSDs for each channel

        Channels need to be in Z, N, E order
        Info on PPSD creation here: https://docs.obspy.org/packages/autogen/obspy.signal.spectral_estimation.PPSD.html
        
        Parameters
        ----------
        params : dict
            Dictionary containing all the parameters and other data of interest (stream and paz, for example)
        remove_outliers : bool, default=True
            Whether to remove outlier h/v curves. This is recommended, particularly if remove_noise() has been used.
        outlier_std :  float, default=3
            The standard deviation value to use as a threshold for determining whether a curve is an outlier. 
            This averages over the entire curve so that curves with very abberant data (often occurs when using the remove_noise() method), can be identified.
        **kwargs : dict
            Dictionary with keyword arguments that are passed directly to obspy.signal.PPSD.
            If the following keywords are not specified, their defaults are amended in this function from the obspy defaults for its PPSD function. Specifically:
                - ppsd_length defaults to 60 (seconds) here instead of 3600
                - skip_on_gaps defaults to True instead of False
                - period_step_octaves defaults to 0.03125 instead of 0.125

        Returns
        -------
            ppsds   :   dict
                Dictionary containing entries with ppsds for each channel
    &#34;&#34;&#34;
    paz=params[&#39;paz&#39;]
    stream = params[&#39;stream&#39;]

    #Set defaults here that are different than obspy defaults
    if &#39;ppsd_length&#39; not in ppsd_kwargs:
        ppsd_kwargs[&#39;ppsd_length&#39;] = 60
    if &#39;skip_on_gaps&#39; not in ppsd_kwargs:
        ppsd_kwargs[&#39;skip_on_gaps&#39;] = True
    if &#39;period_step_octaves&#39; not in ppsd_kwargs:
        ppsd_kwargs[&#39;period_step_octaves&#39;] = 0.03125

    from obspy.signal import PPSD

    eStream = stream.select(component=&#39;E&#39;)
    estats = eStream.traces[0].stats
    ppsdE = PPSD(estats, paz[&#39;E&#39;],  **ppsd_kwargs)
    #ppsdE = PPSD(stream.select(component=&#39;E&#39;).traces[0].stats, paz[&#39;E&#39;], ppsd_length=ppsd_length, kwargs=kwargs)
    ppsdE.add(stream, verbose=verbose)

    nStream = stream.select(component=&#39;N&#39;)
    nstats = nStream.traces[0].stats
    ppsdN = PPSD(nstats, paz[&#39;N&#39;], **ppsd_kwargs)
    ppsdN.add(stream, verbose=verbose)

    zStream = stream.select(component=&#39;Z&#39;)
    zstats = zStream.traces[0].stats
    ppsdZ = PPSD(zstats, paz[&#39;Z&#39;], **ppsd_kwargs)
    ppsdZ.add(stream, verbose=verbose)

    ppsds = {&#39;Z&#39;:ppsdZ, &#39;N&#39;:ppsdN, &#39;E&#39;:ppsdE}

    #Add to the input dictionary, so that some items can be manipulated later on, and original can be saved
    params[&#39;ppsds_obspy&#39;] = ppsds
    params[&#39;ppsds&#39;] = {}
    anyKey = list(params[&#39;ppsds_obspy&#39;].keys())[0]
    
    #Get ppsd class members
    members = [mems for mems in dir(params[&#39;ppsds_obspy&#39;][anyKey]) if not callable(mems) and not mems.startswith(&#34;_&#34;)]
    params[&#39;ppsds&#39;][&#39;Z&#39;] = {}
    params[&#39;ppsds&#39;][&#39;E&#39;] = {}
    params[&#39;ppsds&#39;][&#39;N&#39;] = {}
    
    #Get lists that we may need to manipulate later and copy everything over to main &#39;ppsds&#39; subdictionary (convert lists to np.arrays for consistency)
    listList = [&#39;times_data&#39;, &#39;times_gaps&#39;, &#39;times_processed&#39;,&#39;current_times_used&#39;, &#39;psd_values&#39;]
    for m in members:
        params[&#39;ppsds&#39;][&#39;Z&#39;][m] = getattr(params[&#39;ppsds_obspy&#39;][&#39;Z&#39;], m)
        params[&#39;ppsds&#39;][&#39;E&#39;][m] = getattr(params[&#39;ppsds_obspy&#39;][&#39;E&#39;], m)
        params[&#39;ppsds&#39;][&#39;N&#39;][m] = getattr(params[&#39;ppsds_obspy&#39;][&#39;N&#39;], m)
        if m in listList:
            params[&#39;ppsds&#39;][&#39;Z&#39;][m] = np.array(params[&#39;ppsds&#39;][&#39;Z&#39;][m])
            params[&#39;ppsds&#39;][&#39;E&#39;][m] = np.array(params[&#39;ppsds&#39;][&#39;E&#39;][m])
            params[&#39;ppsds&#39;][&#39;N&#39;][m] = np.array(params[&#39;ppsds&#39;][&#39;N&#39;][m])

    #Create dict entry to keep track of how many outlier hvsr curves are removed (2-item list with [0]=current number, [1]=original number of curves)
    params[&#39;tsteps_used&#39;] = [params[&#39;ppsds&#39;][&#39;Z&#39;][&#39;times_processed&#39;].shape[0], params[&#39;ppsds&#39;][&#39;Z&#39;][&#39;times_processed&#39;].shape[0]]
    
    #Remove outlier ppsds (those derived from data within the windows to be removed)
    if remove_outliers and &#39;xwindows_out&#39; in params.keys():
        params = remove_outlier_ppsds(params, outlier_std=outlier_std, ppsd_length=ppsd_kwargs[&#39;ppsd_length&#39;])
    params[&#39;tsteps_used&#39;][0] = params[&#39;ppsds&#39;][&#39;Z&#39;][&#39;current_times_used&#39;].shape[0]
    
    return params</code></pre>
</details>
</dd>
<dt id="sprit.get_char"><code class="name flex">
<span>def <span class="ident">get_char</span></span>(<span>in_char)</span>
</code></dt>
<dd>
<div class="desc"><p>Outputs character with proper encoding/decoding</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_char(in_char):
    &#34;&#34;&#34;Outputs character with proper encoding/decoding&#34;&#34;&#34;
    if in_char in greek_chars.keys():
        out_char = greek_chars[in_char].encode(encoding=&#39;utf-8&#39;)
    else:
        out_char = in_char.encode(encoding=&#39;utf-8&#39;)
    return out_char.decode(&#39;utf-8&#39;)</code></pre>
</details>
</dd>
<dt id="sprit.get_metadata"><code class="name flex">
<span>def <span class="ident">get_metadata</span></span>(<span>params, write_path='')</span>
</code></dt>
<dd>
<div class="desc"><p>Get metadata and calculate or get paz parameter needed for PPSD</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>params</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dictionary containing all the input and other parameters needed for processing
Ouput from input_params() function</dd>
<dt><strong><code>write_path</code></strong> :&ensp;<code>str</code></dt>
<dd>String with output filepath of where to write updated inventory or metadata file
If not specified, does not write file</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>params</code></strong> :&ensp;<code>dict</code></dt>
<dd>Modified input dictionary with additional key:value pair containing paz dictionary (key = "paz")</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_metadata(params, write_path=&#39;&#39;):
    &#34;&#34;&#34;Get metadata and calculate or get paz parameter needed for PPSD

    Parameters
    ----------
    params : dict
        Dictionary containing all the input and other parameters needed for processing
            Ouput from input_params() function
    write_path : str
        String with output filepath of where to write updated inventory or metadata file
            If not specified, does not write file 

    Returns
    -------
    params : dict
        Modified input dictionary with additional key:value pair containing paz dictionary (key = &#34;paz&#34;)
    &#34;&#34;&#34;
    invPath = params[&#39;metaPath&#39;]
    raspShakeInstNameList = [&#39;raspberry shake&#39;, &#39;shake&#39;, &#39;raspberry&#39;, &#39;rs&#39;, &#39;rs3d&#39;, &#39;rasp. shake&#39;, &#39;raspshake&#39;]
    if params[&#39;instrument&#39;].lower() in  raspShakeInstNameList:
        params = update_shake_metadata(filepath=invPath, params=params, write_path=write_path)
        params = _read_RS_Metadata(params)
    else:
        print(&#39;{} not currently supported\n Returning input params dictionary.&#39;.format(params[&#39;instrument&#39;]))
        return params
    
    return params</code></pre>
</details>
</dd>
<dt id="sprit.gui"><code class="name flex">
<span>def <span class="ident">gui</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Function to open a window with a graphical user interface (gui)</p>
<p>No parameters, no returns; just opens the gui window.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def gui():
    &#34;&#34;&#34;Function to open a window with a graphical user interface (gui)
    
    No parameters, no returns; just opens the gui window.
    &#34;&#34;&#34;
    #guiPath = pathlib.Path(os.path.realpath(__file__))
    #print(guiPath.joinpath(&#39;gui/tkgui.py&#39;).as_posix())
    from sprit.sprit_gui import App
    import tkinter as tk

    def on_gui_closing():
        plt.close(&#39;all&#39;)
        gui_root.quit()
        gui_root.destroy()

    gui_root = tk.Tk()
    gui_root.iconbitmap(pathlib.Path(os.path.dirname(__file__).parent).joinpath(&#34;/resources/sprit_icon_alpha.ico&#34;))
    App(master=gui_root) #Open the app with a tk.Tk root

    gui_root.protocol(&#34;WM_DELETE_WINDOW&#34;, on_gui_closing)    
    gui_root.mainloop() #Run the main loop</code></pre>
</details>
</dd>
<dt id="sprit.hvplot"><code class="name flex">
<span>def <span class="ident">hvplot</span></span>(<span>hvsr_dict, kind='HVSR', use_subplots=True, xtype='freq', fig=None, ax=None, return_fig=False, save_dir=None, save_suffix='', show=True, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Function to plot HVSR data</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>hvsr_dict</code></strong> :&ensp;<code>dict
</code></dt>
<dd>Dictionary containing output from process_hvsr function</dd>
<dt><strong><code>kind</code></strong> :&ensp;<code>str='HVSR'</code> or <code>list
</code></dt>
<dd>The kind of plot(s) to plot. If list, will plot all plots listed
'HVSR' : Standard HVSR plot, including standard deviation
- '[HVSR] p' : HVSR plot with best peaks shown
- '[HVSR] p' : HVSR plot with best picked peak shown
<br>
- '[HVSR] p<em> all' : HVSR plot with all picked peaks shown
<br>
- '[HVSR] p</em> t' : HVSR plot with peaks from all time steps in background
<br>
- '[HVSR p* ann] : Annotates plot with peaks
- '[HVSR] -s' : HVSR plots don't show standard deviation
- '[HVSR] t' : HVSR plot with individual hv curves for each time step shown
- '[HVSR] c' : HVSR plot with each components' spectra. Recommended to do this last (or just before 'specgram'), since doing c+ can make the component chart its own chart
'Specgram' : Combined spectrogram of all components
- '[spec]' : basic spectrogram plot of H/V curve</dd>
<dt><strong><code>use_subplots</code></strong> :&ensp;<code>bool</code>, default <code>= True</code></dt>
<dd>Whether to output the plots as subplots (True) or as separate plots (False)</dd>
<dt><strong><code>xtype</code></strong> :&ensp;<code>str</code>, default <code>= 'freq'</code></dt>
<dd>String for what to use, between frequency or period
For frequency, the following are accepted (case does not matter): 'f', 'Hz', 'freq', 'frequency'
For period, the following are accepted (case does not matter): 'p', 'T', 's', 'sec', 'second', 'per', 'period'</dd>
</dl>
<p>return_fig
: bool
Whether to return figure and axis objects
save_dir
: str or None
Directory in which to save figures
save_suffix
: str
Suffix to add to end of figure filename(s), if save_dir is used
show
: bool
Whether to show plot
**kwargs
: keyword arguments
Keyword arguments for matplotlib.pyplot</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>fig</code></strong>, <strong><code>ax</code></strong> :&ensp;<code>matplotlib figure and axis objects</code></dt>
<dd>Returns figure and axis matplotlib.pyplot objects if return_fig=True, otherwise, simply plots the figures</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def hvplot(hvsr_dict, kind=&#39;HVSR&#39;, use_subplots=True, xtype=&#39;freq&#39;, fig=None, ax=None, return_fig=False,  save_dir=None, save_suffix=&#39;&#39;, show=True,**kwargs):
    &#34;&#34;&#34;Function to plot HVSR data

    Parameters
    ----------
    hvsr_dict : dict                  
        Dictionary containing output from process_hvsr function
    kind : str=&#39;HVSR&#39; or list    
        The kind of plot(s) to plot. If list, will plot all plots listed
        &#39;HVSR&#39; : Standard HVSR plot, including standard deviation
        - &#39;[HVSR] p&#39; : HVSR plot with best peaks shown
        - &#39;[HVSR] p&#39; : HVSR plot with best picked peak shown                
        - &#39;[HVSR] p* all&#39; : HVSR plot with all picked peaks shown                
        - &#39;[HVSR] p* t&#39; : HVSR plot with peaks from all time steps in background                
        - &#39;[HVSR p* ann] : Annotates plot with peaks
        - &#39;[HVSR] -s&#39; : HVSR plots don&#39;t show standard deviation
        - &#39;[HVSR] t&#39; : HVSR plot with individual hv curves for each time step shown
        - &#39;[HVSR] c&#39; : HVSR plot with each components&#39; spectra. Recommended to do this last (or just before &#39;specgram&#39;), since doing c+ can make the component chart its own chart
        &#39;Specgram&#39; : Combined spectrogram of all components
        - &#39;[spec]&#39; : basic spectrogram plot of H/V curve
    use_subplots : bool, default = True
        Whether to output the plots as subplots (True) or as separate plots (False)
    xtype : str, default = &#39;freq&#39;    
        String for what to use, between frequency or period
            For frequency, the following are accepted (case does not matter): &#39;f&#39;, &#39;Hz&#39;, &#39;freq&#39;, &#39;frequency&#39;
            For period, the following are accepted (case does not matter): &#39;p&#39;, &#39;T&#39;, &#39;s&#39;, &#39;sec&#39;, &#39;second&#39;, &#39;per&#39;, &#39;period&#39;
    return_fig   : bool
        Whether to return figure and axis objects
    save_dir     : str or None
        Directory in which to save figures
    save_suffix  : str
        Suffix to add to end of figure filename(s), if save_dir is used
    show    : bool
        Whether to show plot
    **kwargs    : keyword arguments
        Keyword arguments for matplotlib.pyplot

    Returns
    -------
    fig, ax : matplotlib figure and axis objects
        Returns figure and axis matplotlib.pyplot objects if return_fig=True, otherwise, simply plots the figures
    &#34;&#34;&#34;

    compList = [&#39;c&#39;, &#39;comp&#39;, &#39;component&#39;, &#39;components&#39;]
    specgramList = [&#39;spec&#39;, &#39;specgram&#39;, &#39;spectrogram&#39;]
    hvsrList = [&#39;hvsr&#39;, &#39;hv&#39;, &#39;h&#39;]

    hvsrInd = np.nan
    compInd = np.nan
    specInd = np.nan

    kList = kind.split(&#39; &#39;)
    for i, k in enumerate(kList):
        kList[i] = k.lower()

    #HVSR index
    if len(set(hvsrList).intersection(kList)):
        for i, hv in enumerate(hvsrList):
            if hv in kList:
                hvsrInd = kList.index(hv)
                break
    #Component index
    #if len(set(compList).intersection(kList)):
    for i, c in enumerate(kList):
        if &#39;+&#39; in c and c[:-1] in compList:
            compInd = kList.index(c)
            break
        
    #Specgram index
    if len(set(specgramList).intersection(kList)):
        for i, sp in enumerate(specgramList):
            if sp in kList:
                specInd = kList.index(sp)
                break        

    indList = [hvsrInd, compInd, specInd]
    indListCopy = indList.copy()
    plotTypeList = [&#39;hvsr&#39;, &#39;comp&#39;, &#39;spec&#39;]

    plotTypeOrder = []
    plotIndOrder = []

    lastVal = 0
    while lastVal != 99:
        firstInd = np.nanargmin(indListCopy)
        plotTypeOrder.append(plotTypeList[firstInd])
        plotIndOrder.append(indList[firstInd])
        lastVal = indListCopy[firstInd]
        indListCopy[firstInd] = 99 #high number

    plotTypeOrder.pop()
    plotIndOrder[-1]=len(kList)

    for i, p in enumerate(plotTypeOrder):
        pStartInd = plotIndOrder[i]
        pEndInd = plotIndOrder[i+1]
        plotComponents = kList[pStartInd:pEndInd]

        if use_subplots and i==0 and fig is None and ax is None:
            mosaicPlots = []
            for pto in plotTypeOrder:
                mosaicPlots.append([pto])
            fig, ax = plt.subplot_mosaic(mosaicPlots)
            axis = ax[p]
        elif use_subplots:
            axis = ax[p]
        else:
            fig, axis = plt.subplots()
            
        if p == &#39;hvsr&#39;:
            plot_hvsr(hvsr_dict, fig=fig, ax=axis, kind=plotComponents, xtype=&#39;x_freqs&#39;)
        elif p==&#39;comp&#39;:
            plotComponents[0] = plotComponents[0][:-1]
            plot_hvsr(hvsr_dict, fig=fig, ax=axis, kind=plotComponents, xtype=&#39;x_freqs&#39;)
        elif p==&#39;spec&#39;:
            plot_specgram_hvsr(hvsr_dict, fig=fig, ax=axis)
        else:
            print(&#39;Error&#39;)    
    
    if return_fig:
        return fig, ax
    return</code></pre>
</details>
</dd>
<dt id="sprit.info"><code class="name flex">
<span>def <span class="ident">info</span></span>(<span>info_message)</span>
</code></dt>
<dd>
<div class="desc"><p>Prints an informative message</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def info(info_message):
    &#34;&#34;&#34;Prints an informative message&#34;&#34;&#34;
    print(&#34;[INFO] %s&#34; % info_message, flush=True)
    return</code></pre>
</details>
</dd>
<dt id="sprit.input_params"><code class="name flex">
<span>def <span class="ident">input_params</span></span>(<span>dataPath, site='HVSR Site', network='AM', station='RAC84', loc='00', channels=['EHZ', 'EHN', 'EHE'], acq_date='2023-05-23', starttime='00:00:00.00', endtime='23:59:59.999', tzone='UTC', dst=True, lon=-88.2290526, lat=40.1012122, elevation=755, depth=0, instrument='Raspberry Shake', metaPath='', hvsr_band=[0.4, 40])</span>
</code></dt>
<dd>
<div class="desc"><p>Function for designating input parameters for reading in and processing data</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dataPath</code></strong> :&ensp;<code>str</code> or <code>pathlib.Path object</code></dt>
<dd>Filepath of data. This can be a directory or file, but will need to match with what is chosen later as the source parameter in fetch_data()</dd>
<dt><strong><code>site</code></strong> :&ensp;<code>str</code></dt>
<dd>Site name as designated by scientist for ease of reference. Used for plotting titles, etc.</dd>
<dt><strong><code>network</code></strong> :&ensp;<code>str</code>, default=<code>'AM'</code></dt>
<dd>The network designation of the seismometer. This is necessary for data from Raspberry Shakes. 'AM' is for Amateur network, which fits Raspberry Shakes.</dd>
<dt><strong><code>station</code></strong> :&ensp;<code>str</code>, default=<code>'RAC84'</code></dt>
<dd>The station name of the seismometer. This is necessary for data from Raspberry Shakes.</dd>
<dt><strong><code>loc</code></strong> :&ensp;<code>str</code>, default=<code>'00'</code></dt>
<dd>Location information of the seismometer.</dd>
<dt><strong><code>channels</code></strong> :&ensp;<code>list</code>, default=<code>['EHZ', 'EHN', 'EHE']</code></dt>
<dd>The three channels used in this analysis, as a list of strings. Preferred that Z component is first, but not necessary</dd>
<dt><strong><code>acq_date</code></strong> :&ensp;<code>str, int, date object,</code> or <code>datetime object</code></dt>
<dd>If string, preferred format is 'YYYY-MM-DD'.
If int, this will be interpreted as the day of year of current year (e.g., 33 would be Feb 2 of current year)
If date or datetime object, this will be the date. Make sure to account for time change when converting to UTC (if UTC is the following day, use the UTC day).</dd>
<dt><strong><code>starttime</code></strong> :&ensp;<code>str, time object,</code> or <code>datetime object</code>, default=<code>'00:00:00.00'</code></dt>
<dd>Start time of data stream. This is necessary for Raspberry Shake data. Format can be either 'HH:MM:SS.micros' or 'HH:MM' at minimum.</dd>
<dt><strong><code>endtime</code></strong> :&ensp;<code>str, time obejct,</code> or <code>datetime object</code>, default=<code>'23:59:99.99'</code></dt>
<dd>End time of data stream. This is necessary for Raspberry Shake data. Same format as starttime</dd>
<dt><strong><code>tzone</code></strong> :&ensp;<code>str</code> or <code>int</code>, default <code>= 'UTC'</code></dt>
<dd>Timezone of input data. If string, 'UTC' will use the time as input directly. Any other string value will assume local time of computer.
If int, should be the int value of the UTC offset (e.g., for American Eastern Standard Time: -5).
This is necessary for Raspberry Shake data.</dd>
<dt><strong><code>dst</code></strong> :&ensp;<code>bool</code>, default=<code>True</code></dt>
<dd>If str used for tzone parameter, this will adjust for daylight savings time. If int is passed to tzone parameter, this is not used. This is necessary for Raspberry Shake data.</dd>
<dt><strong><code>lon</code></strong> :&ensp;<code>float</code>, default=<code>-88.2290526</code></dt>
<dd>Longitude of data point. Not currently used, but will likely be used in future.</dd>
<dt><strong><code>lat</code></strong> :&ensp;<code>float</code>, default=<code>40.1012122</code></dt>
<dd>Latitude of data point. Not currently used, but will likely be used in the future.</dd>
<dt><strong><code>elevation</code></strong> :&ensp;<code>float</code>, default=<code>755</code></dt>
<dd>Surface elevation of data point. Not currently used, but will likely be used in the future.</dd>
<dt><strong><code>depth</code></strong> :&ensp;<code>float</code>, default=<code>0</code></dt>
<dd>Depth of seismometer. Not currently used, but will likely be used in the future.</dd>
<dt><strong><code>instrument</code></strong> :&ensp;<code>str</code> or <code>list {'Raspberry Shake')</code></dt>
<dd>Instrument from which the data was acquired.</dd>
<dt><strong><code>metaPath</code></strong> :&ensp;<code>str</code> or <code>pathlib.Path object</code>, default=<code>''</code></dt>
<dd>Filepath of metadata, in format supported by obspy.read_inventory. If default value of '', will read from resources folder of repository (only supported for Raspberry Shake).</dd>
<dt><strong><code>hvsr_band</code></strong> :&ensp;<code>list</code>, default=<code>[0.4, 40]</code></dt>
<dd>Two-element list containing low and high "corner" frequencies for processing. This can specified again later.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>inputParamDict</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dictionary containing input parameters, including data file path and metadata path. This will be used as an input to other functions.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def input_params( dataPath,
                        site=&#39;HVSR Site&#39;,
                        network=&#39;AM&#39;, 
                        station=&#39;RAC84&#39;, 
                        loc=&#39;00&#39;, 
                        channels=[&#39;EHZ&#39;, &#39;EHN&#39;, &#39;EHE&#39;],
                        acq_date=str(datetime.datetime.now().date()),
                        starttime = &#39;00:00:00.00&#39;,
                        endtime = &#39;23:59:59.999&#39;,
                        tzone = &#39;UTC&#39;,
                        dst = True,
                        lon = -88.2290526,
                        lat =  40.1012122,
                        elevation = 755,
                        depth = 0,
                        instrument = &#39;Raspberry Shake&#39;,
                        metaPath = &#39;&#39;,
                        hvsr_band = [0.4, 40] 
                        ):
    &#34;&#34;&#34;Function for designating input parameters for reading in and processing data
    
    Parameters
    ----------
    dataPath : str or pathlib.Path object
        Filepath of data. This can be a directory or file, but will need to match with what is chosen later as the source parameter in fetch_data()
    site : str
        Site name as designated by scientist for ease of reference. Used for plotting titles, etc.
    network : str, default=&#39;AM&#39;
        The network designation of the seismometer. This is necessary for data from Raspberry Shakes. &#39;AM&#39; is for Amateur network, which fits Raspberry Shakes.
    station : str, default=&#39;RAC84&#39;
        The station name of the seismometer. This is necessary for data from Raspberry Shakes.
    loc : str, default=&#39;00&#39;
        Location information of the seismometer.
    channels : list, default=[&#39;EHZ&#39;, &#39;EHN&#39;, &#39;EHE&#39;]
        The three channels used in this analysis, as a list of strings. Preferred that Z component is first, but not necessary
    acq_date : str, int, date object, or datetime object
        If string, preferred format is &#39;YYYY-MM-DD&#39;. 
        If int, this will be interpreted as the day of year of current year (e.g., 33 would be Feb 2 of current year)
        If date or datetime object, this will be the date. Make sure to account for time change when converting to UTC (if UTC is the following day, use the UTC day).
    starttime : str, time object, or datetime object, default=&#39;00:00:00.00&#39;
        Start time of data stream. This is necessary for Raspberry Shake data. Format can be either &#39;HH:MM:SS.micros&#39; or &#39;HH:MM&#39; at minimum.
    endtime : str, time obejct, or datetime object, default=&#39;23:59:99.99&#39;
        End time of data stream. This is necessary for Raspberry Shake data. Same format as starttime
    tzone : str or int, default = &#39;UTC&#39;
        Timezone of input data. If string, &#39;UTC&#39; will use the time as input directly. Any other string value will assume local time of computer.
        If int, should be the int value of the UTC offset (e.g., for American Eastern Standard Time: -5). 
        This is necessary for Raspberry Shake data.
    dst : bool, default=True
        If str used for tzone parameter, this will adjust for daylight savings time. If int is passed to tzone parameter, this is not used. This is necessary for Raspberry Shake data.
    lon : float, default=-88.2290526
        Longitude of data point. Not currently used, but will likely be used in future.
    lat : float, default=40.1012122
        Latitude of data point. Not currently used, but will likely be used in the future.
    elevation : float, default=755
        Surface elevation of data point. Not currently used, but will likely be used in the future.
    depth : float, default=0
        Depth of seismometer. Not currently used, but will likely be used in the future.
    instrument : str or list {&#39;Raspberry Shake&#39;)
        Instrument from which the data was acquired. 
    metaPath : str or pathlib.Path object, default=&#39;&#39;
        Filepath of metadata, in format supported by obspy.read_inventory. If default value of &#39;&#39;, will read from resources folder of repository (only supported for Raspberry Shake).
    hvsr_band : list, default=[0.4, 40]
        Two-element list containing low and high &#34;corner&#34; frequencies for processing. This can specified again later.
    
    Returns
    -------
    inputParamDict : dict
        Dictionary containing input parameters, including data file path and metadata path. This will be used as an input to other functions.

    &#34;&#34;&#34;

    #Declare obspy here instead of at top of file for (for example) colab, where obspy first needs to be installed on environment
    global obspy
    import obspy

    #Make Sure metapath is all good
    if not pathlib.Path(metaPath).exists() or metaPath==&#39;&#39;:
        if metaPath == &#39;&#39;:
            print(&#39;No metadata file specified!&#39;)
        else:
            print(&#39;Specified metadata file cannot be read!&#39;)
        repoDir = pathlib.Path(os.path.dirname(__file__).parent)
        metaPath= repoDir.joinpath(&#39;/resources/rs3dv7_metadata.inv&#39;).as_posix()
        print(&#39;Using default metadata file for Raspberry Shake v.7 contained in repository at\n&#39;, metaPath)
    else:
        if isinstance(metaPath, pathlib.PurePath):
            metaPath = metaPath.as_posix()
        else:
            metaPath = pathlib.Path(metaPath).as_posix()

    #Reformat times
    if type(acq_date) is datetime.datetime:
        date = str(acq_date.date())
    elif type(acq_date) is datetime.date:
        date=str(acq_date)
    elif type(acq_date) is str:
        date = acq_date
    elif type(acq_date) is int:
        year=datetime.datetime.today().year
        date = str((datetime.datetime(year, 1, 1) + datetime.timedelta(acq_date - 1)).date())
    
    if type(starttime) is str:
        if &#39;T&#39; in starttime:
            date=starttime.split(&#39;T&#39;)[0]
            starttime = starttime.split(&#39;T&#39;)[1]
    elif type(starttime) is datetime.datetime:
        date = str(starttime.date())
        starttime = str(starttime.time())
    elif type(starttime) is datetime.time():
        starttime = str(starttime)
    
    starttime = date+&#34;T&#34;+starttime
    starttime = obspy.UTCDateTime(__formatTime(starttime, tzone=tzone, dst=dst))

    if type(endtime) is str:
        if &#39;T&#39; in endtime:
            date=endtime.split(&#39;T&#39;)[0]
            endtime = endtime.split(&#39;T&#39;)[1]
    elif type(endtime) is datetime.datetime:
        date = str(endtime.date())
        endtime = str(endtime.time())
    elif type(endtime) is datetime.time():
        endtime = str(endtime)

    endtime = date+&#34;T&#34;+endtime
    endtime = obspy.UTCDateTime(__formatTime(endtime, tzone=tzone, dst=dst))

    acq_date = datetime.date(year=int(date.split(&#39;-&#39;)[0]), month=int(date.split(&#39;-&#39;)[1]), day=int(date.split(&#39;-&#39;)[2]))
    raspShakeInstNameList = [&#39;raspberry shake&#39;, &#39;shake&#39;, &#39;raspberry&#39;, &#39;rs&#39;, &#39;rs3d&#39;, &#39;rasp. shake&#39;, &#39;raspshake&#39;]
    
    #Raspberry shake stationxml is in the resources folder, double check we have right path
    if instrument.lower() in  raspShakeInstNameList:
        if metaPath == r&#39;resources/rs3dv7_metadata.inv&#39;:
            metaPath = pathlib.Path(os.path.realpath(__file__)).parent.joinpath(&#39;/resources/rs3dv7_metadata.inv&#39;)

    #Add key/values to input parameter dictionary
    inputParamDict = {&#39;net&#39;:network,&#39;sta&#39;:station, &#39;loc&#39;:loc, &#39;cha&#39;:channels, &#39;instrument&#39;:instrument,
                    &#39;acq_date&#39;:acq_date,&#39;starttime&#39;:starttime,&#39;endtime&#39;:endtime, &#39;timezone&#39;:&#39;UTC&#39;,
                    &#39;longitude&#39;:lon,&#39;latitude&#39;:lat,&#39;elevation&#39;:elevation,&#39;depth&#39;:depth, &#39;site&#39;:site,
                    &#39;dataPath&#39;:dataPath, &#39;metaPath&#39;:metaPath, &#39;hvsr_band&#39;:hvsr_band
                    }

    return inputParamDict</code></pre>
</details>
</dd>
<dt id="sprit.message"><code class="name flex">
<span>def <span class="ident">message</span></span>(<span>post_message)</span>
</code></dt>
<dd>
<div class="desc"><p>Prints a run message</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def message(post_message):
    &#34;&#34;&#34;Prints a run message&#34;&#34;&#34;
    bar = &#34;*&#34; * 12
    print(&#34;%s %s %s&#34; % (bar, post_message, bar))</code></pre>
</details>
</dd>
<dt id="sprit.plot_hvsr"><code class="name flex">
<span>def <span class="ident">plot_hvsr</span></span>(<span>hvsr_dict, kind, xtype, fig=None, ax=None, save_dir=None, save_suffix='', show=True, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Private function for plotting hvsr curve (or curves with components)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_hvsr(hvsr_dict, kind, xtype, fig=None, ax=None, save_dir=None, save_suffix=&#39;&#39;, show=True, **kwargs):
    &#34;&#34;&#34;Private function for plotting hvsr curve (or curves with components)
    &#34;&#34;&#34;
    if &#39;kwargs&#39; in kwargs.keys():
        kwargs = kwargs[&#39;kwargs&#39;]

    if fig is None and ax is None:
        fig, ax = plt.subplots()

    if &#39;xlim&#39; not in kwargs.keys():
        xlim = hvsr_dict[&#39;hvsr_band&#39;]
    else:
        xlim = kwargs[&#39;xlim&#39;]
    
    if &#39;ylim&#39; not in kwargs.keys():
        ylim = [0, max(hvsr_dict[&#39;hvsrp2&#39;])]
    else:
        ylim = kwargs[&#39;ylim&#39;]
    
    if &#39;grid&#39; in kwargs.keys():
        plt.grid(which=kwargs[&#39;grid&#39;], alpha=0.25)

    if xtype==&#39;x_freqs&#39;:
        xlabel = &#39;Frequency [Hz]&#39;
    else:
        xlabel = &#39;Period [s]&#39;

    if save_dir is not None:
        filename = hvsr_dict[&#39;input_params&#39;][&#39;site&#39;]
    else:
        filename = &#34;&#34;

    #ax = plt.gca()
    #fig = plt.gcf()

    anyKey = list(hvsr_dict[xtype].keys())[0]
    x = hvsr_dict[xtype][anyKey][:-1]
    y = hvsr_dict[&#39;hvsr_curve&#39;]
    
    plotSuff=&#39;&#39;
    legendLoc = &#39;upper right&#39;
    
    plotHVSR = False
    for item in kind:
        if item.lower()==&#39;hvsr&#39;:
            plotHVSR=True
            ax.plot(x, y, color=&#39;k&#39;, label=&#39;H/V Ratio&#39;, zorder=1000)
            plotSuff=&#39;HVSRCurve_&#39;
            if &#39;-s&#39; not in kind:
                ax.fill_between(x, hvsr_dict[&#39;hvsrm2&#39;], hvsr_dict[&#39;hvsrp2&#39;], color=&#39;k&#39;, alpha=0.2, label=&#39;StDev&#39;,zorder=997)
                ax.plot(x, hvsr_dict[&#39;hvsrm2&#39;], color=&#39;k&#39;, alpha=0.25, linewidth=0.5, zorder=998)
                ax.plot(x, hvsr_dict[&#39;hvsrp2&#39;], color=&#39;k&#39;, alpha=0.25, linewidth=0.5, zorder=999)
            else:
                plotSuff = plotSuff+&#39;noStdDev_&#39;
            break

    ax.semilogx()
    ax.set_ylim(ylim)
    ax.set_xlim(xlim)
    ax.set_xlabel(xlabel)
    ax.set_ylabel(&#39;H/V Ratio&#39;+&#39;\n[&#39;+hvsr_dict[&#39;method&#39;]+&#39;]&#39;)
    ax.set_title(hvsr_dict[&#39;input_params&#39;][&#39;site&#39;])


    for k in kind:   
        if k==&#39;p&#39; and &#39;all&#39; not in kind:
            plotSuff=plotSuff+&#39;BestPeak_&#39;
            
            bestPeakScore = 0
            for i, p in enumerate(hvsr_dict[&#39;Peak Report&#39;]):
                if p[&#39;Score&#39;] &gt; bestPeakScore:
                    bestPeakScore = p[&#39;Score&#39;]
                    bestPeak = p

            ax.axvline(bestPeak[&#39;f0&#39;],color=&#39;k&#39;, linestyle=&#39;dotted&#39;, label=&#39;Peak&#39;)          
            if &#39;ann&#39; in kind:
                ax.annotate(&#39;Peak at &#39;+str(round(bestPeak[&#39;f0&#39;],2))+&#39;Hz&#39;, (bestPeak[&#39;f0&#39;], ax.get_ylim()[0]), xycoords=&#39;data&#39;, 
                                horizontalalignment=&#39;center&#39;, verticalalignment=&#39;bottom&#39;, 
                                bbox=dict(facecolor=&#39;w&#39;, edgecolor=&#39;none&#39;, alpha=0.8, pad=0.1))
                plotSuff = plotSuff+&#39;ann_&#39;

        elif k==&#39;p&#39;  and &#39;all&#39; in kind:
            plotSuff = plotSuff+&#39;allPeaks_&#39;

            ax.vlines(hvsr_dict[&#39;hvsr_peak_freqs&#39;], ax.get_ylim()[0], ax.get_ylim()[1], colors=&#39;k&#39;, linestyles=&#39;dotted&#39;, label=&#39;Peak&#39;)          
            if &#39;ann&#39; in kind:
                for i, p in enumerate(hvsr_dict[&#39;hvsr_peak_freqs&#39;]):
                    y = hvsr_dict[&#39;hvsr_curve&#39;][hvsr_dict[&#39;hvsr_peak_indices&#39;][i]]
                    ax.annotate(&#39;Peak at &#39;+str(round(p,2))+&#39;Hz&#39;, (p, 0.1), xycoords=&#39;data&#39;, 
                                    horizontalalignment=&#39;center&#39;, verticalalignment=&#39;bottom&#39;, 
                                    bbox=dict(facecolor=&#39;w&#39;, edgecolor=&#39;none&#39;, alpha=0.8, pad=0.1))
                plotSuff=plotSuff+&#39;ann_&#39;

        if &#39;t&#39; in k:
            plotSuff = plotSuff+&#39;allTWinCurves_&#39;

            if k==&#39;tp&#39;:
                for j, t in enumerate(hvsr_dict[&#39;ind_hvsr_peak_indices&#39;]):
                    for i, v in enumerate(t):
                        v= x[v]
                        if i==0:
                            width = (x[i+1]-x[i])/16
                        else:
                            width = (x[i]-x[i-1])/16
                        if j == 0 and i==0:
                            ax.fill_betweenx(ylim,v-width,v+width, color=&#39;r&#39;, alpha=0.05, label=&#39;Individual H/V Peaks&#39;)
                        else:
                           ax.fill_betweenx(ylim,v-width,v+width, color=&#39;r&#39;, alpha=0.05)
            for t in hvsr_dict[&#39;ind_hvsr_curves&#39;]:
                ax.plot(x, t, color=&#39;k&#39;, alpha=0.15, linewidth=0.8, linestyle=&#39;:&#39;)

        if &#39;c&#39; in k:
            plotSuff = plotSuff+&#39;IndComponents_&#39;
            
            if kind[0] != &#39;c&#39;:
                fig.tight_layout()
                axis2 = ax.twinx()
                compAxis = axis2
                #axis2 = plt.gca()
                #fig = plt.gcf()
                compAxis.set_ylabel(&#39;Amplitude&#39;+&#39;\n[m2/s4/Hz] [dB]&#39;)
                compAxis.set_facecolor([0,0,0,0])
                legendLoc2 = &#39;upper left&#39;
                
            else:
                ax.set_title(hvsr_dict[&#39;input_params&#39;][&#39;site&#39;]+&#39;: Individual Components&#39;)
                #ax = plt.gca()
                #fig = plt.gcf()
                compAxis = ax
                legendLoc2 = &#39;upper right&#39;
                
            minY = []
            maxY = []
            for key in hvsr_dict[&#39;psd_values_tavg&#39;]:
                minY.append(min(hvsr_dict[&#39;ppsd_std_vals_m&#39;][key]))
                maxY.append(max(hvsr_dict[&#39;ppsd_std_vals_p&#39;][key]))
            minY = min(minY)
            maxY = max(maxY)
            rng = maxY-minY
            pad = rng * 0.05
            ylim = [minY-pad, maxY+pad]
        
            compAxis.set_ylabel(&#39;Amplitude&#39;+&#39;\n[m2/s4/Hz] [dB]&#39;)
            compAxis.set_ylim(ylim)

            #Modify based on whether there are multiple charts
            if plotHVSR:
                linalpha = 0.2
                stdalpha = 0.05
            else:
                linalpha=1
                stdalpha=0.2
            
            #Plot individual components
            y={}
            for key in hvsr_dict[&#39;psd_values_tavg&#39;]:
                y[key] = hvsr_dict[&#39;psd_values_tavg&#39;][key][:-1]

                if key == &#39;Z&#39;:
                    pltColor = &#39;k&#39;
                elif key ==&#39;E&#39;:
                    pltColor = &#39;b&#39;
                elif key == &#39;N&#39;:
                    pltColor = &#39;r&#39;

                compAxis.plot(x, y[key], c=pltColor, label=key, alpha=linalpha)
                if &#39;-s&#39; not in kind:
                    compAxis.fill_between(x, hvsr_dict[&#39;ppsd_std_vals_m&#39;][key][:-1], hvsr_dict[&#39;ppsd_std_vals_p&#39;][key][:-1], color=pltColor, alpha=stdalpha)
                if kind[0] != &#39;c&#39;:
                    compAxis.legend(loc=legendLoc2)
            else:
                pass#ax.legend(loc=legendLoc)

    bbox = ax.get_window_extent()
    bboxStart = bbox.__str__().find(&#39;Bbox(&#39;,0,50)+5
    bboxStr = bbox.__str__()[bboxStart:].split(&#39;,&#39;)[:4]
    axisbox = []
    for i in bboxStr:
        i = i.split(&#39;=&#39;)[1]
        if &#39;)&#39; in i:
            i = i[:-1]
        axisbox.append(float(i))
    #print(axisbox)
    #print(ax.get_position())

    ax.legend(loc=legendLoc)

    __plot_current_fig(save_dir=save_dir, 
                        filename=filename, 
                        fig=fig, ax=ax,
                        plot_suffix=plotSuff, 
                        user_suffix=save_suffix, 
                        show=show)
    
    return fig, ax</code></pre>
</details>
</dd>
<dt id="sprit.plot_specgram_hvsr"><code class="name flex">
<span>def <span class="ident">plot_specgram_hvsr</span></span>(<span>hvsr_dict, fig=None, ax=None, save_dir=None, save_suffix='', **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Private function for plotting average spectrogram of all three channels from ppsds</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_specgram_hvsr(hvsr_dict, fig=None, ax=None, save_dir=None, save_suffix=&#39;&#39;,**kwargs):
    &#34;&#34;&#34;Private function for plotting average spectrogram of all three channels from ppsds
    &#34;&#34;&#34;
    if fig is None and ax is None:
        fig, ax = plt.subplots()    

    if &#39;kwargs&#39; in kwargs.keys():
        kwargs = kwargs[&#39;kwargs&#39;]

    if &#39;peak_plot&#39; in kwargs.keys():
        peak_plot=True
        del kwargs[&#39;peak_plot&#39;]
    else:
        peak_plot=False
        

    if &#39;grid&#39; in kwargs.keys():
        ax.grid(which=kwargs[&#39;grid&#39;], alpha=0.25)
        del kwargs[&#39;grid&#39;]
        
    if &#39;ytype&#39; in kwargs:
        if kwargs[&#39;ytype&#39;]==&#39;freq&#39;:
            ylabel = &#39;Frequency [Hz]&#39;
            del kwargs[&#39;ytype&#39;]
        else:
            ylabel = &#39;Period [s]&#39;
        del kwargs[&#39;ytype&#39;]
    else:
        ylabel=&#39;Frequency [Hz]&#39;
        
    if &#39;detrend&#39; in kwargs.keys():
        detrend= kwargs[&#39;detrend&#39;]
        del kwargs[&#39;detrend&#39;]
    else:
        detrend=True

    if &#39;colorbar&#39; in kwargs.keys():
        colorbar = kwargs[&#39;colorbar&#39;]
        del kwargs[&#39;colorbar&#39;]
    else:
        colorbar=True

    if &#39;cmap&#39; in kwargs.keys():
        pass
    else:
        kwargs[&#39;cmap&#39;] = &#39;turbo&#39;

    ppsds = hvsr_dict[&#39;ppsds&#39;]#[k][&#39;current_times_used&#39;]
    import matplotlib.dates as mdates
    anyKey = list(ppsds.keys())[0]

    psdHList =[]
    psdZList =[]
    for k in hvsr_dict[&#39;psd_raw&#39;]:
        if &#39;z&#39; in k.lower():
            psdZList.append(hvsr_dict[&#39;psd_raw&#39;][k])    
        else:
            psdHList.append(hvsr_dict[&#39;psd_raw&#39;][k])
    
    #if detrend:
    #    psdArr = np.subtract(psdArr, np.median(psdArr, axis=0))
    psdArr = hvsr_dict[&#39;ind_hvsr_curves&#39;].T

    xmin = datetime.datetime.strptime(min(hvsr_dict[&#39;ppsds&#39;][anyKey][&#39;current_times_used&#39;][:-1]).isoformat(), &#39;%Y-%m-%dT%H:%M:%S.%f&#39;)
    xmax = datetime.datetime.strptime(max(hvsr_dict[&#39;ppsds&#39;][anyKey][&#39;current_times_used&#39;][:-1]).isoformat(), &#39;%Y-%m-%dT%H:%M:%S.%f&#39;)
    xmin = mdates.date2num(xmin)
    xmax = mdates.date2num(xmax)

    tTicks = mdates.MinuteLocator(byminute=range(0,60,5))
    ax.xaxis.set_major_locator(tTicks)
    tTicks_minor = mdates.SecondLocator(bysecond=[0])
    ax.xaxis.set_minor_locator(tTicks_minor)

    tLabels = mdates.DateFormatter(&#39;%H:%M&#39;)
    ax.xaxis.set_major_formatter(tLabels)
    ax.tick_params(axis=&#39;x&#39;, labelsize=8)

    if hvsr_dict[&#39;ppsds&#39;][anyKey][&#39;current_times_used&#39;][0].date != hvsr_dict[&#39;ppsds&#39;][anyKey][&#39;current_times_used&#39;][-1].date:
        day = str(hvsr_dict[&#39;ppsds&#39;][anyKey][&#39;current_times_used&#39;][0].date)+&#39; - &#39;+str(hvsr_dict[&#39;ppsds&#39;][anyKey][&#39;current_times_used&#39;][1].date)
    else:
        day = str(hvsr_dict[&#39;ppsds&#39;][anyKey][&#39;current_times_used&#39;][0].date)

    ymin = hvsr_dict[&#39;input_params&#39;][&#39;hvsr_band&#39;][0]
    ymax = hvsr_dict[&#39;input_params&#39;][&#39;hvsr_band&#39;][1]

    extList = [xmin, xmax, ymin, ymax]
  
    #ax = plt.gca()
    #fig = plt.gcf()

    freqticks = np.flip(hvsr_dict[&#39;x_freqs&#39;][anyKey])
    yminind = np.argmin(np.abs(ymin-freqticks))
    ymaxind = np.argmin(np.abs(ymax-freqticks))
    freqticks = freqticks[yminind:ymaxind]

    #Set up axes, since data is already in semilog
    axy = ax.twinx()
    axy.zorder=0
    ax.zorder=1
    ax.set_facecolor(&#39;#ffffff00&#39;) #Create transparent background for front axis
    #plt.sca(axy)
    im = ax.imshow(psdArr, origin=&#39;lower&#39;, extent=extList, aspect=&#39;auto&#39;, interpolation=&#39;nearest&#39;, **kwargs)
    ax.tick_params(left=False, right=False)
    ax.set_yticks([], labels=&#39;&#39;)
    #plt.sca(ax)
    if peak_plot:
        ax.hlines(hvsr_dict[&#39;Best Peak&#39;][&#39;f0&#39;], xmin, xmax, colors=&#39;k&#39;, linestyles=&#39;dashed&#39;, alpha=0.5)

    #FreqTicks =np.arange(1,np.round(max(hvsr_dict[&#39;x_freqs&#39;][anyKey]),0), 10)
    ax.set_title(hvsr_dict[&#39;input_params&#39;][&#39;site&#39;]+&#39;: Spectrogram&#39;)
    ax.set_xlabel(&#39;UTC Time \n&#39;+day)
    
    if colorbar:
        cbar = plt.colorbar(mappable=im)
        cbar.set_label(&#39;H/V Ratio&#39;)

    ax.set_ylabel(ylabel)
    #plt.yticks(freqticks)
    #ax.semilogy()
    ax.set_ylim(hvsr_dict[&#39;input_params&#39;][&#39;hvsr_band&#39;])

    #plt.rcParams[&#39;figure.dpi&#39;] = 500
    #plt.rcParams[&#39;figure.figsize&#39;] = (12,4)
    fig.canvas.draw()
    fig.tight_layout()
    #plt.show()
    return fig, ax</code></pre>
</details>
</dd>
<dt id="sprit.plot_specgram_stream"><code class="name flex">
<span>def <span class="ident">plot_specgram_stream</span></span>(<span>stream, params=None, component='Z', stack_type='linear', detrend='mean', dbscale=True, return_fig=True, fig=None, ax=None, cmap_per=[0.1, 0.9], **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Function for plotting spectrogram in a nice matplotlib chart from an obspy.stream</p>
<p>For more details on main function being called, see <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.specgram.html">https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.specgram.html</a> </p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>stream</code></strong> :&ensp;<code>obspy.core.stream.Stream object</code></dt>
<dd>Stream for which to plot spectrogram</dd>
<dt><strong><code>params</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>If dict, will read the hvsr_band from the a dictionary with a key ['hvsr_band'] (like the parameters dictionary). Otherwise, can read in the hvsr_band as a two-item list. Or, if None, defaults to [0.4,40], by default None.</dd>
<dt><strong><code>component</code></strong> :&ensp;<code>str</code> or <code>list</code>, default=<code>'Z'</code></dt>
<dd>If string, should be one character long component, by default 'Z.' If list, can contain 'E', 'N', 'Z', and will stack them per stack_type and stream.stack() method in obspy to make spectrogram.</dd>
<dt><strong><code>stack_type</code></strong> :&ensp;<code>str</code>, default <code>= 'linear'</code></dt>
<dd>Parameter to be read directly into stack_type parameter of Stream.stack() method of obspy streams, by default 'linear'. See <a href="https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.stack.html">https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.stack.html</a>
Only matters if more than one component used.</dd>
<dt><strong><code>detrend</code></strong> :&ensp;<code>str</code>, default <code>= 'mean'</code></dt>
<dd>Parameter to be read directly into detrend parameter of matplotlib.pyplot.specgram, by default 'mean'. See: <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.specgram.html">https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.specgram.html</a></dd>
<dt><strong><code>dbscale</code></strong> :&ensp;<code>bool</code>, default <code>= True</code></dt>
<dd>If True, scale parameter of matplotlib.pyplot.specgram set to 'dB', by default True</dd>
<dt><strong><code>return_fig</code></strong> :&ensp;<code>bool</code>, default <code>= True</code></dt>
<dd>Whether to return the figure from the function or just show it, by default True</dd>
<dt><strong><code>cmap_per</code></strong> :&ensp;<code>list</code>, default <code>= [0.1, 0.9]</code></dt>
<dd>Two-item list wwith clip limits as percentage of values of colormap, so extremes do not taint colormap, by default [0.1,0.9]</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>fig</code></dt>
<dd>If return_fig is True, matplotlib figure is returned</dd>
<dt><code>ax</code></dt>
<dd>If return_fig is True, matplotlib axis is returned</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_specgram_stream(stream, params=None, component=&#39;Z&#39;, stack_type=&#39;linear&#39;, detrend=&#39;mean&#39;, dbscale=True, return_fig=True, fig=None, ax=None, cmap_per=[0.1,0.9], **kwargs):
    &#34;&#34;&#34;Function for plotting spectrogram in a nice matplotlib chart from an obspy.stream

    For more details on main function being called, see https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.specgram.html 

    Parameters
    ----------
    stream : obspy.core.stream.Stream object
        Stream for which to plot spectrogram
    params : dict, optional
        If dict, will read the hvsr_band from the a dictionary with a key [&#39;hvsr_band&#39;] (like the parameters dictionary). Otherwise, can read in the hvsr_band as a two-item list. Or, if None, defaults to [0.4,40], by default None.
    component : str or list, default=&#39;Z&#39;
        If string, should be one character long component, by default &#39;Z.&#39; If list, can contain &#39;E&#39;, &#39;N&#39;, &#39;Z&#39;, and will stack them per stack_type and stream.stack() method in obspy to make spectrogram.
    stack_type : str, default = &#39;linear&#39;
        Parameter to be read directly into stack_type parameter of Stream.stack() method of obspy streams, by default &#39;linear&#39;. See https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.stack.html
        Only matters if more than one component used.
    detrend : str, default = &#39;mean&#39;
        Parameter to be read directly into detrend parameter of matplotlib.pyplot.specgram, by default &#39;mean&#39;. See: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.specgram.html
    dbscale : bool, default = True
        If True, scale parameter of matplotlib.pyplot.specgram set to &#39;dB&#39;, by default True
    return_fig : bool, default = True
        Whether to return the figure from the function or just show it, by default True
    cmap_per : list, default = [0.1, 0.9]
        Two-item list wwith clip limits as percentage of values of colormap, so extremes do not taint colormap, by default [0.1,0.9]

    Returns
    -------
    fig
        If return_fig is True, matplotlib figure is returned
    ax
        If return_fig is True, matplotlib axis is returned
    &#34;&#34;&#34;
    og_stream = stream.copy()

    #Get the latest start time and earliest end times of all components
    traceList = []
    maxStartTime = obspy.UTCDateTime(-1e10) #Go back pretty far (almost 400 years) to start with
    minEndTime = obspy.UTCDateTime(1e10)
    for comp in [&#39;E&#39;, &#39;N&#39;, &#39;Z&#39;]:
        tr = stream.select(component=comp).copy()
        if comp in component:
            traceList.append(tr[0])
        if tr[0].stats.starttime &gt; maxStartTime:
            maxStartTime = tr[0].stats.starttime
        if tr[0].stats.endtime &lt; minEndTime:
            minEndTime = tr[0].stats.endtime

    #Trim all traces to the same start/end time
    for tr in traceList:
        tr.trim(starttime=maxStartTime, endtime=minEndTime)
    og_stream.trim(starttime=maxStartTime, endtime=minEndTime)      

    #Combine all traces into single, stacked trace/stream
    stream = obspy.Stream(traceList)
    stream.stack(group_by=&#39;all&#39;, npts_tol=200, stack_type=stack_type)  

    if fig is None and ax is None:
        #Organize the chart layout
        mosaic = [[&#39;spec&#39;],[&#39;spec&#39;],[&#39;spec&#39;],
                [&#39;spec&#39;],[&#39;spec&#39;],[&#39;spec&#39;],
                [&#39;signalz&#39;],[&#39;signalz&#39;], [&#39;signaln&#39;], [&#39;signale&#39;]]
        fig, ax = plt.subplot_mosaic(mosaic, sharex=True)  
        #fig, ax = plt.subplots(nrows=2, ncols=1, sharex=True)  

    data = stream[0].data
    sample_rate = stream[0].stats.sampling_rate

    if &#39;cmap&#39; in kwargs.keys():
        cmap=kwargs[&#39;cmap&#39;]
    else:
        cmap=&#39;turbo&#39;

    if params is None:
        hvsr_band = [0.4, 40]
    else:
        hvsr_band = params[&#39;hvsr_band&#39;]
    ymin = hvsr_band[0]
    ymax = hvsr_band[1]

    if dbscale:
        scale=&#39;dB&#39;
    else:
        scale=None
    spec, freqs, times, im = ax[&#39;spec&#39;].specgram(x=data, Fs=sample_rate, detrend=detrend, scale_by_freq=True, scale=scale)
    im.remove()

    difference_array = freqs-ymin
    for i, d in enumerate(difference_array):
        if d &gt; 0:
            if i-1 &lt; 0:
                i=1
            minfreqInd = i-1
            break
            
    difference_array = freqs-ymax
    for i, d in enumerate(difference_array):
        if d &gt; 0:
            maxfreqInd = i-1
            break

    array_displayed = spec[minfreqInd:maxfreqInd,:]
    #freqs_displayed = freqs[minfreqInd:maxfreqInd]
    #im.set_data(array_displayed)
    vmin = np.percentile(array_displayed, cmap_per[0]*100)
    vmax = np.percentile(array_displayed, cmap_per[1]*100)
    
    decimation_factor = 10

    sTime = stream[0].stats.starttime
    timeList = {}
    mplTimes = {}
    
    #Decimate data (seems to bring up lots of issues later)
    #if isinstance(og_stream[0].data, np.ma.MaskedArray):
    #    for trace in og_stream:
    #        #unmasked = trace.data[~np.ma.getmask(trace.data)]
    #        decimated_data = scipy.signal.decimate(trace.data, decimation_factor)
    #        decimated_mask = trace.data.mask[::decimation_factor]
    #        print(len(decimated_data))
    #        print(len(decimated_mask))
    #        trace.data = np.ma.array(decimated_data, mask=decimated_mask)
    #        trace.data = np.ma.filled(trace.data, np.nan)
    #else:
    #    og_stream.decimate(decimation_factor)
    og_stream.decimate(decimation_factor)
    for i, tr in enumerate(og_stream):
        key = tr.stats.component
        timeList[key] = [] 
        mplTimes[key] = []
        for t in tr.times():
            t = sTime + t
            timeList[key].append(t)
            mplTimes[key].append(t.matplotlib_date)
    
    for i, k in enumerate(mplTimes.keys()):
        if i == 0:
            xmin = np.min(mplTimes[k])
            xmax = np.max(mplTimes[k])
        else:
            if xmin &gt; np.min(mplTimes[k]):
                xmin = np.min(mplTimes[k])
            if xmax &lt; np.max(mplTimes[k]):
                xmax = np.max(mplTimes[k])         
                   
    norm = matplotlib.colors.Normalize(vmin=vmin, vmax=vmax)
    im = ax[&#39;spec&#39;].imshow(array_displayed, norm=norm, cmap=cmap, aspect=&#39;auto&#39;, interpolation=None, extent=[xmin,xmax,ymax,ymin])

    ax[&#39;spec&#39;].set_xlim([xmin, xmax])
    ax[&#39;spec&#39;].set_ylim([ymin, ymax])
    ax[&#39;spec&#39;].semilogy() 
    
    #cbar = plt.colorbar(mappable=im)
    #cbar.set_label(&#39;Power Spectral Density [dB]&#39;)
    #stream.spectrogram(samp_rate=sample_rate, axes=ax, per_lap=0.75, log=True, title=title, cmap=&#39;turbo&#39;, dbscale=dbscale, show=False)
    
    ax[&#39;spec&#39;].xaxis_date()
    ax[&#39;signalz&#39;].xaxis_date()
    ax[&#39;signaln&#39;].xaxis_date()
    ax[&#39;signale&#39;].xaxis_date()
    #tTicks = mdates.MinuteLocator(interval=5)
    #ax[0].xaxis.set_major_locator(tTicks)
    ax[&#39;signale&#39;].xaxis.set_major_locator(mdates.MinuteLocator(byminute=range(0,60,5)))
    ax[&#39;signale&#39;].xaxis.set_major_formatter(mdates.DateFormatter(&#39;%H:%M&#39;))
    ax[&#39;signale&#39;].xaxis.set_minor_locator(mdates.MinuteLocator(interval=1))
    ax[&#39;signale&#39;].tick_params(axis=&#39;x&#39;, labelsize=8)
    
    ax[&#39;signalz&#39;].plot(mplTimes[&#39;Z&#39;],og_stream.select(component=&#39;Z&#39;)[0].data, color=&#39;k&#39;, linewidth=0.25)
    ax[&#39;signaln&#39;].plot(mplTimes[&#39;N&#39;],og_stream.select(component=&#39;N&#39;)[0].data, color=&#39;k&#39;, linewidth=0.1)
    ax[&#39;signale&#39;].plot(mplTimes[&#39;E&#39;],og_stream.select(component=&#39;E&#39;)[0].data, color=&#39;k&#39;, linewidth=0.1)

    ax[&#39;spec&#39;].set_ylabel(&#39;Spectrogram: {}&#39;.format(component))
    ax[&#39;signalz&#39;].set_ylabel(&#39;Z&#39;)
    ax[&#39;signaln&#39;].set_ylabel(&#39;N&#39;)
    ax[&#39;signale&#39;].set_ylabel(&#39;E&#39;)
    
    for comp in mplTimes.keys():
        stD = np.nanstd(og_stream.select(component=comp)[0].data)
        dmed = np.nanmedian(og_stream.select(component=comp)[0].data)
        key = &#39;signal&#39;+comp.lower()
        ax[key].set_ylim([dmed-5*stD, dmed+5*stD])
    
    if params is None:
        fig.suptitle(&#39;HVSR Site: Spectrogram and Data&#39;)
    elif &#39;title&#39; in kwargs.keys():
        fig.suptitle(kwargs[&#39;title&#39;])
    else:
        fig.suptitle(params[&#39;site&#39;]+&#39;Spectrogram and Data&#39;)
    
    day = &#34;{}-{}-{}&#34;.format(stream[0].stats.starttime.year, stream[0].stats.starttime.month, stream[0].stats.starttime.day)
    ax[&#39;signale&#39;].set_xlabel(&#39;UTC Time \n&#39;+day)

    #plt.rcParams[&#39;figure.dpi&#39;] = 100
    #plt.rcParams[&#39;figure.figsize&#39;] = (5,4)
    
    #fig.tight_layout()
    fig.canvas.draw()
    if return_fig:
        return fig, ax
    return</code></pre>
</details>
</dd>
<dt id="sprit.plot_stream"><code class="name flex">
<span>def <span class="ident">plot_stream</span></span>(<span>stream, params, fig=None, axes=None, return_fig=True)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_stream(stream, params, fig=None, axes=None, return_fig=True):
    if fig is None and ax is None:
        fig, axes = plt.subplot_mosaic([[&#39;Z&#39;],[&#39;N&#39;],[&#39;E&#39;]], sharex=True, sharey=False)
    
    new_stream = stream.copy()
    #axis.plot(trace.times, trace.data)
    
    sTime = stream[0].stats.starttime
    timeList = {}
    mplTimes = {}

    new_stream.decimate(10)
    ztrace = new_stream.select(component=&#39;Z&#39;)[0]
    etrace = new_stream.select(component=&#39;E&#39;)[0]
    ntrace = new_stream.select(component=&#39;N&#39;)[0]
    traces = [ztrace, etrace, ntrace]
    for tr in traces:
        key = tr.stats.component
        timeList[key] = []
        mplTimes[key] = []
        for t in tr.times():
            t = sTime + t
            timeList[key].append(t)
            mplTimes[key].append(t.matplotlib_date)
    for i, k in enumerate(mplTimes.keys()):
        if i == 0:
            xmin = np.min(mplTimes[k])
            xmax = np.max(mplTimes[k])
        else:
            if xmin &gt; np.min(mplTimes[k]):
                xmin = np.min(mplTimes[k])
            if xmax &lt; np.max(mplTimes[k]):
                xmax = np.max(mplTimes[k]) 

    axes[&#39;Z&#39;].xaxis_date()
    axes[&#39;N&#39;].xaxis_date()
    axes[&#39;E&#39;].xaxis_date()

    #tTicks = mdates.MinuteLocator(interval=5)
    #axis.xaxis.set_major_locator(tTicks)
    axes[&#39;E&#39;].xaxis.set_major_locator(mdates.MinuteLocator(byminute=range(0,60,5)))
    axes[&#39;E&#39;].xaxis.set_major_formatter(mdates.DateFormatter(&#39;%H:%M&#39;))
    axes[&#34;E&#34;].xaxis.set_minor_locator(mdates.MinuteLocator(interval=1))
    axes[&#34;E&#34;].tick_params(axis=&#39;x&#39;, labelsize=8)
    
    axes[&#39;Z&#39;].plot(mplTimes[&#39;Z&#39;], ztrace.data, color=&#39;k&#39;, linewidth=0.15)
    axes[&#39;N&#39;].plot(mplTimes[&#39;N&#39;], ntrace.data, color=&#39;b&#39;, linewidth=0.15)
    axes[&#39;E&#39;].plot(mplTimes[&#39;E&#39;], etrace.data, color=&#39;r&#39;, linewidth=0.15)

    axes[&#39;Z&#39;].set_ylabel(&#39;Z&#39;)
    axes[&#39;N&#39;].set_ylabel(&#39;N&#39;)
    axes[&#39;E&#39;].set_ylabel(&#39;E&#39;)
    
    #stDz = np.abs(np.nanstd(stream.select(component=&#39;Z&#39;)[0].data))
    #stDn = np.abs(np.nanstd(stream.select(component=&#39;N&#39;)[0].data))
    #stDe = np.abs(np.nanstd(stream.select(component=&#39;E&#39;)[0].data))
    #stD = max([stDz, stDn, stDe])
    
    for i, comp in enumerate(list(mplTimes.keys())):
        stD = np.abs(np.nanstd(stream.select(component=comp)[0].data))
        dmed = np.nanmedian(stream.select(component=comp)[0].data)

        axes[comp].set_ylim([dmed-0.75*stD, dmed+0.75*stD])
        axes[comp].set_xlim([xmin, xmax])

    fig.suptitle(params[&#39;site&#39;])
    
    day = &#34;{}-{}-{}&#34;.format(stream[0].stats.starttime.year, stream[0].stats.starttime.month, stream[0].stats.starttime.day)
    axes[&#39;E&#39;].set_xlabel(&#39;UTC Time \n&#39;+day)

    #plt.rcParams[&#39;figure.dpi&#39;] = 100
    #plt.rcParams[&#39;figure.figsize&#39;] = (5,4)
    
    fig.tight_layout()

    if return_fig:
        return fig, axes
    fig.canvas.draw()
    return                 </code></pre>
</details>
</dd>
<dt id="sprit.print_report"><code class="name flex">
<span>def <span class="ident">print_report</span></span>(<span>hvsr_data, export='', format='print', include='peak', save_figs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Print a report of the HVSR analysis (not currently implemented)</p>
<p>NOT YET IMPLEMENTED!</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>hvsr_data</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dictionary containing all the information about the processed hvsr data</dd>
<dt><strong><code>format</code></strong> :&ensp;<code>{'csv', 'print', 'docx'}</code></dt>
<dd>Format in which to print or export the report.</dd>
<dt><strong><code>export</code></strong> :&ensp;<code>str</code></dt>
<dd>Filepath path for export. If not specified, report name is generated automatically and placed in current directory</dd>
<dt><strong><code>include</code></strong> :&ensp;<code>str</code> or <code>list</code>, default=<code>'peak'</code></dt>
<dd>What to include in the report. By default includes all the following
- Site name
- Acquisition Date
- Longitude
- Latitude
- Elevation
- Primary peak frequency
- Whether passed quality tests (x6)
For docx (not yet implemented), the following are also included:
- Figure with spectrogram
- Figure with HVSR curve
- Figure with 3 components</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def print_report(hvsr_data, export=&#39;&#39;, format=&#39;print&#39;, include=&#39;peak&#39;, save_figs=None):
    &#34;&#34;&#34;Print a report of the HVSR analysis (not currently implemented)
    
    NOT YET IMPLEMENTED!
    
    Parameters
    ----------
    hvsr_data : dict
        Dictionary containing all the information about the processed hvsr data
    format : {&#39;csv&#39;, &#39;print&#39;, &#39;docx&#39;}
        Format in which to print or export the report.
    export : str
        Filepath path for export. If not specified, report name is generated automatically and placed in current directory
    include : str or list, default=&#39;peak&#39;
        What to include in the report. By default includes all the following
            - Site name
            - Acquisition Date
            - Longitude
            - Latitude
            - Elevation
            - Primary peak frequency
            - Whether passed quality tests (x6)
        For docx (not yet implemented), the following are also included:
            - Figure with spectrogram
            - Figure with HVSR curve
            - Figure with 3 components
    &#34;&#34;&#34;
    #print statement
    if format==&#39;print&#39;:
        print(hvsr_data[&#39;input_params&#39;][&#39;site&#39;])
        print(hvsr_data[&#39;input_params&#39;][&#39;acq_date&#39;])
        print(hvsr_data[&#39;input_params&#39;][&#39;longitude&#39;], hvsr_data[&#39;input_params&#39;][&#39;latitude&#39;])
        print(hvsr_data[&#39;input_params&#39;][&#39;elevation&#39;])
        print(round(hvsr_data[&#39;Best Peak&#39;][&#39;f0&#39;], 3))
        for p in hvsr_data[&#39;Best Peak&#39;][&#34;Pass List&#34;]:
            print(p, &#39;:&#39;,hvsr_data[&#39;Best Peak&#39;][&#34;Pass List&#34;][p])
        print(&#39;Peak Passes Criteria:&#39;,hvsr_data[&#39;Best Peak&#39;][&#34;Peak Passes&#34;])

        hvplot(hvsr_data, kind=&#39;HVSR p tp ann&#39;)
        hvplot(hvsr_data, kind=&#39;HVSR c&#39;)
        hvplot(hvsr_data, kind=&#39;spec&#39;)
    elif format==&#39;csv&#39;:
        import pandas as pd
        pdCols = [&#39;Site Name&#39;, &#39;Acqusition Date&#39;, &#39;Longitude&#39;, &#39;Latitide&#39;, &#39;Elevation&#39;, &#39;Peak Frequency&#39;, 
                  &#39;Window Length Freq.&#39;,&#39;Significant Cycles&#39;,&#39;Low Curve StDev. over time&#39;,
                  &#39;Peak Freq. Clarity Below&#39;,&#39;Peak Freq. Clarity Above&#39;,&#39;Peak Amp. Clarity&#39;,&#39;Freq. Stability&#39;, &#39;Peak Stability (freq. std)&#39;,&#39;Peak Stability (amp. std)&#39;, &#39;Peak Passes&#39;]
        d = hvsr_data
        criteriaList = []
        for p in hvsr_data[&#39;Best Peak&#39;][&#34;Pass List&#34;]:
            criteriaList.append(hvsr_data[&#39;Best Peak&#39;][&#34;Pass List&#34;][p])
        criteriaList.append(hvsr_data[&#39;Best Peak&#39;][&#34;Peak Passes&#34;])
        dfList = [[d[&#39;input_params&#39;][&#39;site&#39;], d[&#39;input_params&#39;][&#39;acq_date&#39;], d[&#39;input_params&#39;][&#39;longitude&#39;], d[&#39;input_params&#39;][&#39;latitude&#39;], d[&#39;input_params&#39;][&#39;elevation&#39;], round(d[&#39;Best Peak&#39;][&#39;f0&#39;], 3)]]
        dfList[0].extend(criteriaList)
        outDF = pd.DataFrame(dfList, columns=pdCols)
        if export==&#39;&#39;:
            inFile = pathlib.Path(hvsr_data[&#39;input_params&#39;][&#39;dataPath&#39;])
            if inFile.is_dir():
                inFile = inFile.as_posix()
                if inFile[-1]==&#39;/&#39;:
                    pass
                else:
                    inFile = inFile + &#39;/&#39;
                fname = hvsr_data[&#39;input_params&#39;][&#39;site&#39;]+&#39;_&#39;+str(hvsr_data[&#39;input_params&#39;][&#39;acq_date&#39;])+&#39;_&#39;+str(hvsr_data[&#39;input_params&#39;][&#39;starttime&#39;].time)[:5]+&#39;-&#39;+str(hvsr_data[&#39;input_params&#39;][&#39;endtime&#39;].time)[:5]
                inFile = inFile + fname +&#39;.csv&#39;
            elif inFile.is_file():
                export = inFile.with_suffix(&#39;.csv&#39;)
        outDF.to_csv(export, index_label=&#39;ID&#39;)
        return outDF
    if export:
        pass
        #code to write to output file
    return</code></pre>
</details>
</dd>
<dt id="sprit.process_hvsr"><code class="name flex">
<span>def <span class="ident">process_hvsr</span></span>(<span>params, method=4, smooth=True, freq_smooth='konno ohmachi', f_smooth_width=40, resample=True, remove_outlier_curves=True, outlier_curve_std=1.75)</span>
</code></dt>
<dd>
<div class="desc"><p>Process the input data and get HVSR data</p>
<p>This is the main function that uses other (private) functions to do
the bulk of processing of the HVSR data and the data quality checks.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt>params
: dict</dt>
<dt>Dictionary containing all the parameters input by the user</dt>
<dt>method
: int or str</dt>
<dt>Method to use for combining the horizontal components</dt>
<dt>0) Diffuse field assumption, or 'DFA' (not currently implemented)</dt>
<dt>1) 'Arithmetic Mean': H â‰¡ (HN + HE)/2</dt>
<dt>2) 'Geometric Mean': H â‰¡ âˆšHN Â· HE, recommended by the SESAME project (2004)</dt>
<dt>3) 'Vector Summation': H â‰¡ âˆšH2 N + H2 E</dt>
<dt>4) 'Quadratic Mean': H â‰¡ âˆš(H2 N + H2 E )/2</dt>
<dt HE HN_="HN,">5) 'Maximum Horizontal Value': H â‰¡ max</dt>
<dt>smooth
: bool=True</dt>
<dt>bool or int.</dt>
<dt>If True, default to smooth H/V curve to using savgoy filter with window length of 51 (works well with default resample of 1000 pts)</dt>
<dt>If int, the length of the window in the savgoy filter.</dt>
<dt><strong><code>freq_smooth</code></strong> :&ensp;<code>str {'konno ohmachi', 'constant', 'proportional'}</code></dt>
<dd>Which frequency smoothing method to use. By default, uses the 'konno ohmachi' method.
- The Konno &amp; Ohmachi method uses the obspy.signal.konnoohmachismoothing.konno_ohmachi_smoothing() function: <a href="https://docs.obspy.org/packages/autogen/obspy.signal.konnoohmachismoothing.konno_ohmachi_smoothing.html">https://docs.obspy.org/packages/autogen/obspy.signal.konnoohmachismoothing.konno_ohmachi_smoothing.html</a>
- The constant method
See here for more information: <a href="https://www.geopsy.org/documentation/geopsy/hv-processing.html">https://www.geopsy.org/documentation/geopsy/hv-processing.html</a></dd>
<dt><strong><code>f_smooth_width</code></strong> :&ensp;<code>int</code>, default <code>= 40</code></dt>
<dd>
<ul>
<li>For 'konno ohmachi': passed directly to the bandwidth parameter of the konno_ohmachi_smoothing() function, determines the width of the smoothing peak, with lower values resulting in broader peak. Must be &gt; 0.</li>
<li>For 'constant': the size of a triangular smoothing window in the number of frequency steps</li>
<li>For 'proportional': the size of a triangular smoothing window in percentage of the number of frequency steps (e.g., if 1000 frequency steps/bins and f_smooth_width=40, window would be 400 steps wide)</li>
</ul>
</dd>
<dt>resample
: bool, default = True</dt>
<dt>bool or int.</dt>
<dt>If True, default to resample H/V data to include 1000 frequency values for the rest of the analysis</dt>
<dt>If int, the number of data points to interpolate/resample/smooth the component psd/HV curve data to.</dt>
<dt><strong><code>remove_outlier_curves</code></strong> :&ensp;<code>bool</code>, default <code>= True</code></dt>
<dd>Whether to remove outlier h/v curves. Recommend to be repeated even after using in generate_ppsds() if remove_noise() is used.</dd>
<dt><strong><code>outlier_curve_std</code></strong> :&ensp;<code>float</code>, default <code>= 1.75</code></dt>
<dd>Standard deviation of mean of each H/V curve to use as cuttoff for whether an H/V curve is considered an 'outlier'</dd>
</dl>
<h2 id="returns">Returns</h2>
<pre><code>hvsr_out    : dict
    Dictionary containing all the information about the data, including input parameters
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def process_hvsr(params, method=4, smooth=True, freq_smooth=&#39;konno ohmachi&#39;, f_smooth_width=40, resample=True, remove_outlier_curves=True, outlier_curve_std=1.75):
    &#34;&#34;&#34;Process the input data and get HVSR data
    
    This is the main function that uses other (private) functions to do 
    the bulk of processing of the HVSR data and the data quality checks.

    Parameters
    ----------
    params  : dict
        Dictionary containing all the parameters input by the user
    method  : int or str
        Method to use for combining the horizontal components
            0) Diffuse field assumption, or &#39;DFA&#39; (not currently implemented)
            1) &#39;Arithmetic Mean&#39;: H â‰¡ (HN + HE)/2
            2) &#39;Geometric Mean&#39;: H â‰¡ âˆšHN Â· HE, recommended by the SESAME project (2004)
            3) &#39;Vector Summation&#39;: H â‰¡ âˆšH2 N + H2 E
            4) &#39;Quadratic Mean&#39;: H â‰¡ âˆš(H2 N + H2 E )/2
            5) &#39;Maximum Horizontal Value&#39;: H â‰¡ max {HN, HE}
    smooth  : bool=True
        bool or int. 
            If True, default to smooth H/V curve to using savgoy filter with window length of 51 (works well with default resample of 1000 pts)
            If int, the length of the window in the savgoy filter.
    freq_smooth : str {&#39;konno ohmachi&#39;, &#39;constant&#39;, &#39;proportional&#39;}
        Which frequency smoothing method to use. By default, uses the &#39;konno ohmachi&#39; method.
            - The Konno &amp; Ohmachi method uses the obspy.signal.konnoohmachismoothing.konno_ohmachi_smoothing() function: https://docs.obspy.org/packages/autogen/obspy.signal.konnoohmachismoothing.konno_ohmachi_smoothing.html
            - The constant method
        See here for more information: https://www.geopsy.org/documentation/geopsy/hv-processing.html
    f_smooth_width : int, default = 40
        - For &#39;konno ohmachi&#39;: passed directly to the bandwidth parameter of the konno_ohmachi_smoothing() function, determines the width of the smoothing peak, with lower values resulting in broader peak. Must be &gt; 0.
        - For &#39;constant&#39;: the size of a triangular smoothing window in the number of frequency steps
        - For &#39;proportional&#39;: the size of a triangular smoothing window in percentage of the number of frequency steps (e.g., if 1000 frequency steps/bins and f_smooth_width=40, window would be 400 steps wide)
    resample  : bool, default = True
        bool or int. 
            If True, default to resample H/V data to include 1000 frequency values for the rest of the analysis
            If int, the number of data points to interpolate/resample/smooth the component psd/HV curve data to.
    remove_outlier_curves : bool, default = True
        Whether to remove outlier h/v curves. Recommend to be repeated even after using in generate_ppsds() if remove_noise() is used.
    outlier_curve_std : float, default = 1.75
        Standard deviation of mean of each H/V curve to use as cuttoff for whether an H/V curve is considered an &#39;outlier&#39;

    Returns
    -------
        hvsr_out    : dict
            Dictionary containing all the information about the data, including input parameters

    &#34;&#34;&#34;
    ppsds = params[&#39;ppsds&#39;].copy()#[k][&#39;psd_values&#39;]
    ppsds = __check_xvalues(ppsds)

    methodList = [&#39;Diffuse Field Assumption&#39;, &#39;Arithmetic Mean&#39;, &#39;Geometric Mean&#39;, &#39;Vector Summation&#39;, &#39;Quadratic Mean&#39;, &#39;Maximum Horizontal Value&#39;]
    x_freqs = {}
    x_periods = {}

    psdValsTAvg = {}
    stDev = {}
    stDevValsP = {}
    stDevValsM = {}
    psdRaw={}
    currTimesUsed={}
    
    for k in ppsds:
        #if reasmpling has been selected
        if resample or type(resample) is int:
            if resample:
                resample = 1000 #Default smooth value

            xValMin = min(ppsds[k][&#39;period_bin_centers&#39;])
            xValMax = max(ppsds[k][&#39;period_bin_centers&#39;])

            #Resample period bin values
            x_periods[k] = np.logspace(np.log10(xValMin), np.log10(xValMax), num=resample)

            if smooth or type(smooth) is int:
                if smooth:
                    smooth = 51 #Default smoothing window
                elif smooth%2==0:
                    smooth = smooth+1

            #Resample raw ppsd values
            for i, t in enumerate(ppsds[k][&#39;psd_values&#39;]):
                if i==0:
                    psdRaw[k] = np.interp(x_periods[k], ppsds[k][&#39;period_bin_centers&#39;], t)
                    if smooth is not False:
                        psdRaw[k] = scipy.signal.savgol_filter(psdRaw[k], smooth, 3)

                else:
                    psdRaw[k] = np.vstack((psdRaw[k], np.interp(x_periods[k], ppsds[k][&#39;period_bin_centers&#39;], t)))
                    if smooth is not False:
                        psdRaw[k][i] = scipy.signal.savgol_filter(psdRaw[k][i], smooth, 3)

        else:
            #If no resampling desired
            x_periods[k] = np.array(ppsds[k][&#39;period_bin_centers&#39;])
            psdRaw[k] = np.array(ppsds[k][&#39;psd_values&#39;])

        #Get average psd value across time for each channel (used to calc main H/V curve)
        psdValsTAvg[k] = np.nanmean(np.array(psdRaw[k]), axis=0)
        x_freqs[k] = np.divide(np.ones_like(x_periods[k]), x_periods[k]) 

        stDev[k] = np.std(psdRaw[k], axis=0)
        stDevValsM[k] = np.array(psdValsTAvg[k] - stDev[k])
        stDevValsP[k] = np.array(psdValsTAvg[k] + stDev[k])

        currTimesUsed[k] = ppsds[k][&#39;current_times_used&#39;]

    #Get string of method type
    if type(method) is int:
        methodInt = method
        method = methodList[method]

    #This gets the hvsr curve averaged from all time steps
    anyK = list(x_freqs.keys())[0]
    hvsr_curve = __get_hvsr_curve(x=x_freqs[anyK], psd=psdValsTAvg, method=methodInt)

    origPPSD = params[&#39;ppsds_obspy&#39;].copy()

    #Add some other variables to our output dictionary
    hvsr_out = {&#39;input_params&#39;:params.copy(),
                &#39;x_freqs&#39;:x_freqs,
                &#39;hvsr_curve&#39;:hvsr_curve,
                &#39;x_period&#39;:x_periods,
                &#39;psd_raw&#39;:psdRaw,
                &#39;current_times_used&#39;: currTimesUsed,
                &#39;psd_values_tavg&#39;:psdValsTAvg,
                &#39;ppsd_std&#39;:stDev,
                &#39;ppsd_std_vals_m&#39;:stDevValsM,
                &#39;ppsd_std_vals_p&#39;:stDevValsP,
                &#39;method&#39;:method,
                &#39;ppsds&#39;:ppsds,
                &#39;ppsds_obspy&#39;:origPPSD,
                &#39;tsteps_used&#39;: params[&#39;tsteps_used&#39;].copy()
                }

    if &#39;xwindows_out&#39; in params.keys():
        hvsr_out[&#39;xwindows_out&#39;] = params[&#39;xwindows_out&#39;]
    else:
        hvsr_out[&#39;xwindows_out&#39;] = []

    del hvsr_out[&#39;input_params&#39;][&#39;ppsds_obspy&#39;]
    del hvsr_out[&#39;input_params&#39;][&#39;ppsds&#39;]
    del hvsr_out[&#39;input_params&#39;][&#39;tsteps_used&#39;]

    freq_smooth_ko = [&#39;konno ohmachi&#39;, &#39;konno-ohmachi&#39;, &#39;konnoohmachi&#39;, &#39;konnohmachi&#39;, &#39;ko&#39;, &#39;k&#39;]
    freq_smooth_constant = [&#39;constant&#39;, &#39;const&#39;, &#39;c&#39;]
    freq_smooth_proport = [&#39;proportional&#39;, &#39;proportion&#39;, &#39;prop&#39;, &#39;p&#39;]

    #Frequency Smoothing
    if freq_smooth is False:
        print(&#39;No frequency smoothing is being applied. This is not recommended for noisy datasets.&#39;)
    elif freq_smooth is True or freq_smooth.lower() in freq_smooth_ko:
        from obspy.signal import konnoohmachismoothing
        for k in hvsr_out[&#39;psd_raw&#39;]:
            ppsd_data = hvsr_out[&#39;psd_raw&#39;][k]
            freqs = hvsr_out[&#39;x_freqs&#39;][k]
            smoothed_ppsd_data = konnoohmachismoothing.konno_ohmachi_smoothing(ppsd_data, freqs, bandwidth=f_smooth_width, normalize=True)
            hvsr_out[&#39;psd_raw&#39;][k] = smoothed_ppsd_data
    elif freq_smooth.lower() in freq_smooth_constant:
        hvsr_out = __freq_smooth_window(hvsr_out, f_smooth_width, kind=&#39;constant&#39;)
    elif freq_smooth.lower() in freq_smooth_proport:
        hvsr_out = __freq_smooth_window(hvsr_out, f_smooth_width, kind=&#39;proportional&#39;)
    else:
        print(&#39;No frequency smoothing is being applied. This is not recommended for noisy datasets.&#39;)


    #Get hvsr curve from three components at each time step
    hvsr_tSteps = []
    anyK = list(hvsr_out[&#39;psd_raw&#39;].keys())[0]
    for tStep in range(len(hvsr_out[&#39;psd_raw&#39;][anyK])):
        tStepDict = {}
        for k in hvsr_out[&#39;psd_raw&#39;]:
            tStepDict[k] = hvsr_out[&#39;psd_raw&#39;][k][tStep]
        hvsr_tSteps.append(__get_hvsr_curve(x=hvsr_out[&#39;x_freqs&#39;][anyK], psd=tStepDict, method=methodInt))
    hvsr_tSteps = np.array(hvsr_tSteps)
    
    hvsr_out[&#39;ind_hvsr_curves&#39;] = hvsr_tSteps

    #use the standard deviation of each individual curve to determine if it overlapped
    if remove_outlier_curves:
        stdT = np.std(hvsr_out[&#39;ind_hvsr_curves&#39;], axis=1)
        std_stdT= np.std(stdT)
        avg_stdT= np.nanmean(stdT)

        psds_to_rid = []
        for i,t in enumerate(hvsr_out[&#39;ind_hvsr_curves&#39;]):
            if stdT[i] &lt; avg_stdT - std_stdT*outlier_curve_std or stdT[i] &gt; avg_stdT + std_stdT*outlier_curve_std:
                psds_to_rid.append(i)

        for i, r in enumerate(psds_to_rid):
            index = int(r-i)
            hvsr_out[&#39;ind_hvsr_curves&#39;] = np.delete(hvsr_out[&#39;ind_hvsr_curves&#39;], index, axis=0)

            for k in hvsr_out[&#39;ppsds&#39;]:
                hvsr_out[&#39;psd_raw&#39;][k] = np.delete(hvsr_out[&#39;psd_raw&#39;][k], index, axis=0)         
                hvsr_out[&#39;current_times_used&#39;][k] = np.delete(hvsr_out[&#39;current_times_used&#39;][k], index)
        hvsr_out[&#39;tsteps_used&#39;][0] = hvsr_out[&#39;ppsds&#39;][k][&#39;current_times_used&#39;].shape[0]

    hvsr_out[&#39;ind_hvsr_stdDev&#39;] = np.std(hvsr_out[&#39;ind_hvsr_curves&#39;], axis=0)

    #Get peaks for each time step
    tStepPeaks = []
    for tStepHVSR in hvsr_tSteps:
        tStepPeaks.append(__find_peaks(tStepHVSR))
    hvsr_out[&#39;ind_hvsr_peak_indices&#39;] = tStepPeaks
    #Get peaks of main HV curve
    hvsr_out[&#39;hvsr_peak_indices&#39;] = __find_peaks(hvsr_out[&#39;hvsr_curve&#39;])
    
    #Get frequency values at HV peaks in main curve
    hvsrPF=[]
    for p in hvsr_out[&#39;hvsr_peak_indices&#39;]:
        hvsrPF.append(hvsr_out[&#39;x_freqs&#39;][anyK][p])
    hvsr_out[&#39;hvsr_peak_freqs&#39;] = np.array(hvsrPF)


    #Get other HVSR parameters (i.e., standard deviations, water levels, etc.)
    hvsr_out = __gethvsrparams(hvsr_out)

    #Include the original obspy stream in the output
    hvsr_out[&#39;stream&#39;] = params[&#39;stream&#39;]

    return hvsr_out</code></pre>
</details>
</dd>
<dt id="sprit.remove_noise"><code class="name flex">
<span>def <span class="ident">remove_noise</span></span>(<span>input, kind='auto', sat_percent=0.995, noise_percent=0.8, sta=2, lta=30, stalta_thresh=[0.5, 5], show_plot=False, warmup_time=0, cooldown_time=0, min_win_size=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Function to remove noisy windows from data, using various methods.</p>
<p>Methods include
- Manual window selection (by clicking on a chart with spectrogram and stream data),
- Auto window selection, which does the following two in sequence (these can also be done indepently):
- A sta/lta "antitrigger" method (using stalta values to automatically remove triggered windows where there appears to be too much noise)
- A noise threshold method, that cuts off all times where the noise threshold equals more than (by default) 99.5% of the highest amplitude noise sample.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>input</code></strong> :&ensp;<code>dict, obspy.Stream,</code> or <code>obspy.Trace</code></dt>
<dd>Dictionary containing all the data and parameters for the HVSR analysis</dd>
<dt><strong><code>kind</code></strong> :&ensp;<code>str, {'auto', 'manual', 'stalta'/'antitrigger', 'noise threshold', 'warmup'/'buffer'}</code></dt>
<dd>The different methods for removing noise from the dataset. See descriptions above for what how each method works. By default 'auto.'</dd>
<dt><strong><code>noise_percent</code></strong> :&ensp;<code>float</code>, default=<code>0.995</code></dt>
<dd>Percentage (between 0 and 1), to use as the threshold at which to remove data. This is used in the noise threshold method. By default 0.995.
If a value is passed that is greater than 1, it will be divided by 100 to obtain the percentage.</dd>
<dt><strong><code>sta</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Short term average (STA) window (in seconds), by default 2.</dd>
<dt><strong><code>lta</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Long term average (STA) window (in seconds), by default 2.</dd>
<dt><strong><code>stalta_thresh</code></strong> :&ensp;<code>list</code>, default=<code>[0.5,5]</code></dt>
<dd>Two-item list or tuple with the thresholds for the stalta antitrigger. The first value (index [0]) is the lower threshold, the second value (index [1] is the upper threshold), by default [0.5,5]</dd>
<dt><strong><code>show_plot</code></strong> :&ensp;<code>bool</code>, default=<code>False</code></dt>
<dd>If True, will plot the trigger and stalta values (if stalta antitrigger method), or the data with the new windows removed (if noise threshold), by default False. Does not apply to 'manual' method.</dd>
<dt><strong><code>warmup_time</code></strong> :&ensp;<code>int</code>, default=<code>0</code></dt>
<dd>Time in seconds to allow for warmup of the instrument. This will renove any data before this time, by default 0.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>output</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dictionary similar to input, but containing modified data with 'noise' removed</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def remove_noise(input, kind=&#39;auto&#39;, sat_percent=0.995, noise_percent=0.80, sta=2, lta=30, stalta_thresh=[0.5,5], show_plot=False, warmup_time=0, cooldown_time=0, min_win_size=1):
    &#34;&#34;&#34;Function to remove noisy windows from data, using various methods.
    
    Methods include 
    - Manual window selection (by clicking on a chart with spectrogram and stream data), 
    - Auto window selection, which does the following two in sequence (these can also be done indepently):
        - A sta/lta &#34;antitrigger&#34; method (using stalta values to automatically remove triggered windows where there appears to be too much noise)
        - A noise threshold method, that cuts off all times where the noise threshold equals more than (by default) 99.5% of the highest amplitude noise sample.

    Parameters
    ----------
    input : dict, obspy.Stream, or obspy.Trace
        Dictionary containing all the data and parameters for the HVSR analysis
    kind : str, {&#39;auto&#39;, &#39;manual&#39;, &#39;stalta&#39;/&#39;antitrigger&#39;, &#39;noise threshold&#39;, &#39;warmup&#39;/&#39;buffer&#39;}
        The different methods for removing noise from the dataset. See descriptions above for what how each method works. By default &#39;auto.&#39;
    noise_percent : float, default=0.995
        Percentage (between 0 and 1), to use as the threshold at which to remove data. This is used in the noise threshold method. By default 0.995. 
        If a value is passed that is greater than 1, it will be divided by 100 to obtain the percentage.
    sta : int, optional
        Short term average (STA) window (in seconds), by default 2.
    lta : int, optional
        Long term average (STA) window (in seconds), by default 2.
    stalta_thresh : list, default=[0.5,5]
        Two-item list or tuple with the thresholds for the stalta antitrigger. The first value (index [0]) is the lower threshold, the second value (index [1] is the upper threshold), by default [0.5,5]
    show_plot : bool, default=False
        If True, will plot the trigger and stalta values (if stalta antitrigger method), or the data with the new windows removed (if noise threshold), by default False. Does not apply to &#39;manual&#39; method.
    warmup_time : int, default=0
        Time in seconds to allow for warmup of the instrument. This will renove any data before this time, by default 0.

    Returns
    -------
    output : dict
        Dictionary similar to input, but containing modified data with &#39;noise&#39; removed
    &#34;&#34;&#34;
    
    manualList = [&#39;manual&#39;, &#39;man&#39;, &#39;m&#39;, &#39;window&#39;, &#39;windows&#39;, &#39;w&#39;]
    autoList = [&#39;auto&#39;, &#39;automatic&#39;, &#39;all&#39;, &#39;a&#39;]
    antitrigger = [&#39;stalta&#39;, &#39;anti&#39;, &#39;antitrigger&#39;, &#39;trigger&#39;, &#39;at&#39;]
    saturationThresh = [&#39;saturation threshold&#39;, &#39;saturation&#39;, &#39;sat&#39;, &#39;s&#39;]
    noiseThresh = [&#39;noise threshold&#39;, &#39;noise&#39;, &#39;threshold&#39;, &#39;n&#39;]
    warmup_cooldown=[&#39;warmup&#39;, &#39;cooldown&#39;, &#39;warm&#39;, &#39;cool&#39;, &#39;buffer&#39;, &#39;warmup-cooldown&#39;, &#39;warmup_cooldown&#39;, &#39;wc&#39;, &#39;warm_cool&#39;, &#39;warm-cool&#39;]

    if isinstance(input,dict):
        if &#39;stream_edited&#39; in input.keys():
            inStream = input[&#39;stream_edited&#39;].copy()
        else:
            inStream = input[&#39;stream&#39;].copy()
        output = input.copy()
    elif isinstance(input, obspy.core.stream.Stream) or isinstance(input, obspy.core.trace.Trace):
        inStream = input.copy()
        output = inStream.copy()
    else:
        print(&#34;ERROR: input is not expected type&#34;)
    
    if kind.lower() in manualList:
        if isinstance(output, dict):
            if &#39;xwindows_out&#39; in output.keys():
                pass
            else:
                output = select_windows(output)
            window_list = output[&#39;xwindows_out&#39;]

        if isinstance(inStream, obspy.core.stream.Stream):
            if window_list is not None:
                output[&#39;stream_edited&#39;] = __remove_windows(inStream, window_list, warmup_time)
            else:
                output = select_windows(output)
        elif type(output) is dict:
            pass
        else:
            print(&#39;ERROR: Using anything other than an obspy stream is not currently supported for this noise removal method.&#39;)
            
    elif kind.lower() in autoList:
        outStream = __remove_noise_thresh(inStream, noise_percent=noise_percent, lta=lta, min_win_size=min_win_size)
        outStream = __remove_anti_stalta(outStream, sta=sta, lta=lta, thresh=stalta_thresh)
        outStream = __remove_noise_saturate(outStream, sat_percent=sat_percent, min_win_size=min_win_size)
        outStream = __remove_warmup_cooldown(stream=outStream, warmup_time=warmup_time, cooldown_time=cooldown_time)
    elif kind.lower() in antitrigger:
        outStream = __remove_anti_stalta(inStream, sta=sta, lta=lta, thresh=stalta_thresh)
    elif kind.lower() in saturationThresh:
        outStream = __remove_noise_saturate(inStream, sat_percent=sat_percent, min_win_size=min_win_size)
    elif kind.lower() in noiseThresh:
        outStream = __remove_noise_thresh(inStream, noise_percent=noise_percent, lta=lta, min_win_size=min_win_size)
    elif kind.lower() in warmup_cooldown:
        outStream = __remove_warmup_cooldown(stream=inStream, warmup_time=warmup_time, cooldown_time=cooldown_time)
    else:
        print(&#34;kind parameter is not recognized. Please choose one of the following: &#39;manual&#39;, &#39;auto&#39;, &#39;antitrigger&#39;, &#39;noise threshold&#39;, &#39;warmup_cooldown&#34;)
        return

    if isinstance(input, dict):
        output[&#39;stream_edited&#39;] = outStream
    elif isinstance(input, obspy.core.stream.Stream) or isinstance(input, obspy.core.trace.Trace):
        output = outStream
    return output</code></pre>
</details>
</dd>
<dt id="sprit.select_windows"><code class="name flex">
<span>def <span class="ident">select_windows</span></span>(<span>input)</span>
</code></dt>
<dd>
<div class="desc"><p>Function to manually select windows for exclusion from data.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>input</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dictionary containing all the hvsr information.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>xWindows</code></strong> :&ensp;<code>list</code></dt>
<dd>List of two-item lists containing start and end times of windows to be removed.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def select_windows(input):
    &#34;&#34;&#34;Function to manually select windows for exclusion from data.

    Parameters
    ----------
    input : dict
        Dictionary containing all the hvsr information.

    Returns
    -------
    xWindows : list
        List of two-item lists containing start and end times of windows to be removed.
    &#34;&#34;&#34;
    from matplotlib.backend_bases import MouseButton
    import matplotlib.pyplot as plt
    import matplotlib
    import time
    global fig
    global ax

    if type(input) is dict:
        if &#39;hvsr_curve&#39; in input.keys():
            fig, ax = hvplot(hvsr_dict=input, kind=&#39;spec&#39;, returnfig=True, cmap=&#39;turbo&#39;)
        else:
            params = input.copy()
            input = input[&#39;stream&#39;]
    
    if isinstance(input, obspy.core.stream.Stream):
        fig, ax = plot_specgram_stream(input, component=[&#39;Z&#39;])
    elif isinstance(input, obspy.core.trace.Trace):
        fig, ax = plot_specgram_stream(input)

    global lineArtist
    global winArtist
    global windowDrawn
    global pathList
    global xWindows
    global clickNo
    global x0
    x0=0
    clickNo = 0
    xWindows = []
    pathList = []
    windowDrawn = []
    winArtist = []
    lineArtist = []

    global fig_closed
    fig_closed = False
    while fig_closed is False:
        fig.canvas.mpl_connect(&#39;button_press_event&#39;, __on_click)#(clickNo, xWindows, pathList, windowDrawn, winArtist, lineArtist, x0, fig, ax))
        fig.canvas.mpl_connect(&#39;close_event&#39;, __on_fig_close)#(clickNo, xWindows, pathList, windowDrawn, winArtist, lineArtist, x0, fig, ax))
        plt.pause(1)

    params[&#39;xwindows_out&#39;] = xWindows
    params[&#39;fig&#39;] = fig
    params[&#39;ax&#39;] = ax
    return params</code></pre>
</details>
</dd>
<dt id="sprit.setup_colab"><code class="name flex">
<span>def <span class="ident">setup_colab</span></span>(<span>option='', repo_dir='')</span>
</code></dt>
<dd>
<div class="desc"><p>Function to help set up Google Colab environment for SPRIT</p>
<p>This is designed to be run twice in a Google Colab environment without any parameters, and at the beginning of the Google Colab notebook.
The first run will install obspy (which is not installed on Colab by default), then restart the kernel (necessary for Colab to run obspy effectively).
The second run will "install" the repository. </p>
<p>This will be changed dramatically once the repository is ready for distrubution via pypi.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>option</code></strong> :&ensp;<code>str</code>, default=<code>''</code></dt>
<dd>Which iteration to run of setup_colab. Be default, this function can determine which "iteration" it needs to run, but it can be specified manually.</dd>
<dt><strong><code>repo_dir</code></strong> :&ensp;<code>str</code> or <code>pathlib.Path</code>, default=<code>''</code></dt>
<dd>Where the repository has been "installed"/extracted in the Colab folder structure.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def setup_colab(option=&#39;&#39;, repo_dir=&#39;&#39;):
    &#34;&#34;&#34;Function to help set up Google Colab environment for SPRIT
    
    This is designed to be run twice in a Google Colab environment without any parameters, and at the beginning of the Google Colab notebook. 
    The first run will install obspy (which is not installed on Colab by default), then restart the kernel (necessary for Colab to run obspy effectively).
    The second run will &#34;install&#34; the repository. 
    
    This will be changed dramatically once the repository is ready for distrubution via pypi.
    
    Parameters
    ----------
    option : str, default=&#39;&#39;
        Which iteration to run of setup_colab. Be default, this function can determine which &#34;iteration&#34; it needs to run, but it can be specified manually.
    repo_dir : str or pathlib.Path, default=&#39;&#39;
        Where the repository has been &#34;installed&#34;/extracted in the Colab folder structure.
        
    Returns
    -------
    None

    &#34;&#34;&#34;
    import datetime
    import math
    import os
    import pathlib
    import time
    import sys
    import subprocess

    import matplotlib.pyplot as plt
    import numpy as np
    import scipy

    from google.colab import files
    from zipfile import ZipFile
    #%matplotlib #Run this line if you want interactive plots
    #https://github.com/googlecolab/colabtools/blob/main/google/colab/_system_commands.py
    from google.colab import _system_commands
    pyvers = _system_commands._run_command(&#39;python --version&#39;, False)
    pyvers = pyvers.output.split(&#39; &#39;)#+pyvers.output.split(&#39;.&#39;)[1]
    pyvers = pyvers[0].lower()+pyvers[1].split(&#39;.&#39;)[0]+&#39;.&#39;+pyvers[1].split(&#39;.&#39;)[1]

    #Setup matplotlib too?
    #_system_commands._run_command(&#39;matplotlib qt&#39;, False)

    packPath = &#39;/usr/local/lib/&#39;+pyvers+&#39;/dist-packages&#39;
    packPath = pathlib.Path(packPath)
    
    #Make directories
    dataDir = &#39;/content/Data/&#39;
    outputDir = &#39;/content/Output&#39;
    if not os.path.exists(dataDir):
        os.makedirs(dataDir)
    if not os.path.exists(outputDir):
        os.makedirs(outputDir)    
    
    obspyInstalled=False
    for f in packPath.iterdir():
        if &#39;obspy&#39; in f.name:
            obspyInstalled=True
            global obspy
            import obspy
            break
        
    if &#39;obspy&#39; in option or option==&#39;&#39;:
        if not obspyInstalled:
            print(&#39;Installing Obspy&#39;)
            _system_commands._run_command(&#39;pip install obspy&#39;, False)
            print(&#34;Runtime will now be reset to properly load obspy&#34;)
            print(&#39;Please run setup_colab() to upload data and enter code environment.&#39;)
            os.kill(os.getpid(), 9)
        else:
            global obspy
            import obspy
            print(&#39;Obspy has been imported.&#39;) 
    elif &#39;data&#39; in option:
        global obspy
        import obspy
        print(&#39;Obspy has been installed imported.&#39;)

        os.chdir(dataDir)
        print(&#39;\nUpload data file(s): \n(file(s) will be placed in &#39;+dataDir+&#39;)&#39;)
        files.upload() #Upload the 3 data files to be used
        if repo_dir == &#39;&#39;:
            repo_dir=&#39;/content/SPRIT&#39;
        os.chdir(repo_dir)
    return</code></pre>
</details>
</dd>
<dt id="sprit.show_removed_windows"><code class="name flex">
<span>def <span class="ident">show_removed_windows</span></span>(<span>input, fig=None, ax=None, lineArtist=[], winArtist=[], existing_lineArtists=[], keep_line_artists=True, time_type='matplotlib')</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def show_removed_windows(input, fig=None, ax=None, lineArtist =[], winArtist = [], existing_lineArtists=[], keep_line_artists=True, time_type=&#39;matplotlib&#39;):
    if fig is None and ax is None:
        fig, ax = plt.subplots()

    if type(input) is dict:
        if &#39;stream_edited&#39; in input.keys():
            stream = input[&#39;stream_edited&#39;].copy()
        else:
            stream = input[&#39;stream&#39;].copy()
    else:
        stream = input.copy()

    #Get masked indices of trace(s)
    trace = stream[0]
    windows = []
    windows.append([0,np.nan])

    #mask = np.isnan(trace.data)  # Create a mask for None values
    #masked_array = np.ma.array(trace.data, mask=mask).copy()
    masked_array = trace.data.copy()

    if isinstance(masked_array, np.ma.MaskedArray):
        sample_rate = trace.stats.sampling_rate
        masked_array = masked_array.mask.nonzero()[0]
        lastMaskInd = masked_array[0]
        wInd = 0
        #masked_array = trace.data.mask.nonzero()[0]
        for i in range(1, len(masked_array)):
            maskInd = masked_array[i]
            if maskInd-lastMaskInd &gt; 1:
                windows.append([np.nan, np.nan])
                windows[wInd][1] = masked_array[i - 1]
                wInd += 1
                windows[wInd][0] = masked_array[i]

            lastMaskInd = maskInd    
        windows[wInd][1] = masked_array[-1]

        #Reformat ax as needed
        if isinstance(ax, np.ndarray):
            origAxes = ax.copy()
            newAx = {}
            for i, a in enumerate(ax):
                newAx[i] = a
            axes = newAx
        elif isinstance(ax, dict):
            origAxes = ax
            axes = ax
        else:
            origAxes = ax
            axes = {&#39;ax&#39;:ax}

        samplesList = [&#39;sample&#39;, &#39;samples&#39;, &#39;s&#39;]
        utcList = [&#39;utc&#39;, &#39;utcdatetime&#39;, &#39;obspy&#39;, &#39;u&#39;, &#39;o&#39;]
        matplotlibList = [&#39;matplotlib&#39;, &#39;mpl&#39;, &#39;m&#39;]    

        for i, a in enumerate(axes.keys()):
            ax = axes[a]
            pathList = []
            
            windowDrawn = []
            winArtist = []
            if existing_lineArtists == []:
                lineArtist = []
            elif len(existing_lineArtists)&gt;=1 and keep_line_artists:
                lineArtist = existing_lineArtists
            else:
                lineArtist = []

            for winNums, win in enumerate(windows):
                if time_type.lower() in samplesList:
                    x0 = win[0]
                    x1 = win[1]
                elif time_type.lower() in utcList or time_type.lower() in matplotlibList:
                    sample_rate = trace.stats.delta

                    x0 = trace.stats.starttime + win[0] * sample_rate
                    x1 = trace.stats.starttime + win[1] * sample_rate

                    if time_type.lower() in matplotlibList:
                        x0 = x0.matplotlib_date
                        x1 = x1.matplotlib_date
                else:
                    print(&#39;time_type error&#39;)
                
                y0, y1 = ax.get_ylim()

                path_data = [
                            (matplotlib.path.Path.MOVETO, (x0, y0)),
                            (matplotlib.path.Path.LINETO, (x1, y0)),
                            (matplotlib.path.Path.LINETO, (x1, y1)),
                            (matplotlib.path.Path.LINETO, (x0, y1)),
                            (matplotlib.path.Path.LINETO, (x0, y0)),
                            (matplotlib.path.Path.CLOSEPOLY, (x0, y0)),
                        ]
                
                codes, verts = zip(*path_data)
                path = matplotlib.path.Path(verts, codes)

                #
                windowDrawn.append(False)
                winArtist.append(None)
                lineArtist.append([])
                linArt0 = ax.axvline(x0, y0, y1, color=&#39;k&#39;, linewidth=0.5, zorder=100)
                linArt1 = plt.axvline(x1, y0, y1, color=&#39;k&#39;, linewidth=0.5, zorder=100)
                lineArtist[winNums].append([linArt0, linArt1])
                #
                
                pathList.append(path)

            for i, pa in enumerate(pathList):
                if windowDrawn[i]:
                    pass
                else:
                    patch = matplotlib.patches.PathPatch(pa, facecolor=&#39;k&#39;, alpha=0.75)                            
                    winArt = ax.add_patch(patch)
                    windowDrawn[i] = True
                    winArtist[i] = winArt
            
            #Reformat ax as needed
            if isinstance(origAxes, np.ndarray):
                origAxes[i] = ax
            elif isinstance(origAxes, dict):
                origAxes[a] = ax
            else:
                origAxes = ax

        ax = origAxes

        fig.canvas.draw()

    return fig, ax, lineArtist, winArtist</code></pre>
</details>
</dd>
<dt id="sprit.time_it"><code class="name flex">
<span>def <span class="ident">time_it</span></span>(<span>_t)</span>
</code></dt>
<dd>
<div class="desc"><p>Computes elapsed time since the last call.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def time_it(_t):
    &#34;&#34;&#34;Computes elapsed time since the last call.&#34;&#34;&#34;
    t1 = datetime.datetime.now().time()
    dt = t1 - _t
    t = _t
    if dt &gt; 0.05:
        #print(f&#39;[TIME] {dt:0.1f} s&#39;, flush=True)
        t = t1
    return t</code></pre>
</details>
</dd>
<dt id="sprit.trim_data"><code class="name flex">
<span>def <span class="ident">trim_data</span></span>(<span>stream, params, export_dir=None, export_format=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Function to trim data to start and end time</p>
<p>Trim data to start and end times so that stream being analyzed only contains wanted data.
Can also export data to specified directory using a specified site name and/or export_format</p>
<h2 id="parameters">Parameters</h2>
<pre><code>stream  : obspy.stream object  
    Obspy stream to be trimmed
params  : dict
    Dictionary containing input parameters for trimming
export_dir: str or pathlib obj   
    Output filepath to export trimmed data to. If not specified, does not export. 
export_format  : str or None, default=None  
    If None, and export_dir is specified, format defaults to .mseed. Otherwise, exports trimmed stream using obspy.core.stream.Stream.write() method, with export_format being passed to the format argument. 
    &lt;https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.write.html#obspy.core.stream.Stream.write&gt;
**kwargs
    Keyword arguments passed directly to obspy.core.stream.Stream.trim() method. starttime and endtime parameters are already provided through the params parameter, so should not be passed as kwargs.
</code></pre>
<h2 id="returns">Returns</h2>
<pre><code>st_trimmed  : obspy.stream object 
    Obpsy Stream trimmed to start and end times
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def trim_data(stream, params, export_dir=None, export_format=None, **kwargs):
    &#34;&#34;&#34;Function to trim data to start and end time

        Trim data to start and end times so that stream being analyzed only contains wanted data.
        Can also export data to specified directory using a specified site name and/or export_format

        Parameters
        ----------
            stream  : obspy.stream object  
                Obspy stream to be trimmed
            params  : dict
                Dictionary containing input parameters for trimming
            export_dir: str or pathlib obj   
                Output filepath to export trimmed data to. If not specified, does not export. 
            export_format  : str or None, default=None  
                If None, and export_dir is specified, format defaults to .mseed. Otherwise, exports trimmed stream using obspy.core.stream.Stream.write() method, with export_format being passed to the format argument. 
                https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.write.html#obspy.core.stream.Stream.write
            **kwargs
                Keyword arguments passed directly to obspy.core.stream.Stream.trim() method. starttime and endtime parameters are already provided through the params parameter, so should not be passed as kwargs.
                
        Returns
        -------
            st_trimmed  : obspy.stream object 
                Obpsy Stream trimmed to start and end times
    &#34;&#34;&#34;
    start = params[&#39;starttime&#39;]
    end = params[&#39;endtime&#39;]
    site = params[&#39;site&#39;]

    st_trimmed = stream.copy()

    trimStart = obspy.UTCDateTime(start)
    trimEnd = obspy.UTCDateTime(end)
    for tr in st_trimmed:
        if trimStart &gt; tr.stats.endtime or trimEnd &lt; tr.stats.starttime:
            pass
        else:
            st_trimmed.trim(starttime=trimStart, endtime=trimEnd, **kwargs)
    st_trimmed.merge(method=1)

    #Format export filepath, if exporting
    if export_format is not None and site is not None and export_dir is not None:
        if site is None:
            site=&#39;&#39;
        else:
            site = site+&#39;_&#39;
        export_format = &#39;.&#39;+export_format
        net = st_trimmed[0].stats.network
        sta = st_trimmed[0].stats.station
        loc = st_trimmed[0].stats.location
        yr = str(st_trimmed[0].stats.starttime.year)
        strtD=str(st_trimmed[0].stats.starttime.date)
        strtT=str(st_trimmed[0].stats.starttime.time)[0:2]
        strtT=strtT+str(st_trimmed[0].stats.starttime.time)[3:5]
        endT = str(st_trimmed[0].stats.endtime.time)[0:2]
        endT = endT+str(st_trimmed[0].stats.endtime.time)[3:5]
        doy = str(st_trimmed[0].stats.starttime.utctimetuple().tm_yday).zfill(3)

        export_dir = checkifpath(export_dir)
        export_dir = str(export_dir)
        export_dir = export_dir.replace(&#39;\\&#39;, &#39;/&#39;)
        export_dir = export_dir.replace(&#39;\\&#39;[0], &#39;/&#39;)

        if type(export_format) is str:
            filename = site+net+&#39;.&#39;+sta+&#39;.&#39;+loc+&#39;.&#39;+yr+&#39;.&#39;+doy+&#39;_&#39;+strtD+&#39;_&#39;+strtT+&#39;-&#39;+endT+export_format
        elif type(export_format) is bool:
            filename = site+net+&#39;.&#39;+sta+&#39;.&#39;+loc+&#39;.&#39;+yr+&#39;.&#39;+doy+&#39;_&#39;+strtD+&#39;_&#39;+strtT+&#39;-&#39;+endT+&#39;.mseed&#39;

        if export_dir[-1]==&#39;/&#39;:
            export_dir=export_dir[:-1]
        
        exportFile = export_dir+&#39;/&#39;+filename

        st_trimmed.write(filename=exportFile)
    else:
        pass

    return st_trimmed</code></pre>
</details>
</dd>
<dt id="sprit.update_shake_metadata"><code class="name flex">
<span>def <span class="ident">update_shake_metadata</span></span>(<span>filepath, params, write_path='')</span>
</code></dt>
<dd>
<div class="desc"><p>Reads static metadata file provided for Rasp Shake and updates with input parameters. Used primarily in the get_metadata() function.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code> or <code>pathlib.Path object</code></dt>
<dd>Filepath to metadata file. Should be a file format supported by obspy.read_inventory().</dd>
<dt><strong><code>params</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dictionary containing necessary keys/values for updating, currently only supported for STATIONXML with Raspberry Shakes.
Necessary keys: 'net', 'sta',
Optional keys: 'longitude', 'latitude', 'elevation', 'depth'</dd>
</dl>
<p>write_path
: str, default=''
If specified, filepath to write to updated inventory file to.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>params</code></strong> :&ensp;<code>dict</code></dt>
<dd>Updated params dict with new key:value pair with updated updated obspy.inventory object (key="inv")</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_shake_metadata(filepath, params, write_path=&#39;&#39;):
    &#34;&#34;&#34;Reads static metadata file provided for Rasp Shake and updates with input parameters. Used primarily in the get_metadata() function.

        PARAMETERS
        ----------
        filepath : str or pathlib.Path object
            Filepath to metadata file. Should be a file format supported by obspy.read_inventory().
        params : dict
            Dictionary containing necessary keys/values for updating, currently only supported for STATIONXML with Raspberry Shakes.
                Necessary keys: &#39;net&#39;, &#39;sta&#39;, 
                Optional keys: &#39;longitude&#39;, &#39;latitude&#39;, &#39;elevation&#39;, &#39;depth&#39;
        write_path   : str, default=&#39;&#39;
            If specified, filepath to write to updated inventory file to.

        Returns
        -------
        params : dict
            Updated params dict with new key:value pair with updated updated obspy.inventory object (key=&#34;inv&#34;)
    &#34;&#34;&#34;

    network = params[&#39;net&#39;]
    station = params[&#39;sta&#39;]
    optKeys = [&#39;longitude&#39;, &#39;latitude&#39;, &#39;elevation&#39;, &#39;depth&#39;]
    for k in optKeys:
        if k not in params.keys():
            params[k] = &#39;0&#39;
    lon = str(params[&#39;longitude&#39;])
    lat = str(params[&#39;latitude&#39;])
    elevation = str(params[&#39;elevation&#39;])
    depth = str(params[&#39;depth&#39;])
    
    startdate = str(datetime.datetime(year=2023, month=2, day=15)) #First day with working code
    enddate=str(datetime.datetime.today())

    filepath = checkifpath(filepath)

    tree = ET.parse(str(filepath))
    root = tree.getroot()

    prefix= &#34;{http://www.fdsn.org/xml/station/1}&#34;

    for item in root.iter(prefix+&#39;Channel&#39;):
        item.attrib[&#39;startDate&#39;] = startdate
        item.attrib[&#39;endDate&#39;] = enddate

    for item in root.iter(prefix+&#39;Station&#39;):
        item.attrib[&#39;code&#39;] = station
        item.attrib[&#39;startDate&#39;] = startdate
        item.attrib[&#39;endDate&#39;] = enddate

    for item in root.iter(prefix+&#39;Network&#39;):
        item.attrib[&#39;code&#39;] = network
        
    for item in root.iter(prefix+&#39;Latitude&#39;):
        item.text = lat

    for item in root.iter(prefix+&#39;Longitude&#39;):
        item.text = lon

    for item in root.iter(prefix+&#39;Created&#39;):
        nowTime = str(datetime.datetime.now())
        item.text = nowTime

    for item in root.iter(prefix+&#39;Elevation&#39;):
        item.text= elevation

    for item in root.iter(prefix+&#39;Depth&#39;):
        item.text=depth

    #Set up (and) export
    #filetag = &#39;_&#39;+str(datetime.datetime.today().date())
    #outfile = str(parentPath)+&#39;\\&#39;+filename+filetag+&#39;.inv&#39;

    if write_path != &#39;&#39;:
        tree.write(write_path, xml_declaration=True, method=&#39;xml&#39;,encoding=&#39;UTF-8&#39;)
        inv = obspy.read_inventory(write_path, format=&#39;STATIONXML&#39;, level=&#39;response&#39;)
    else:
        #Create temporary file for reading into obspy
        tpf = tempfile.NamedTemporaryFile(delete=False)
        stringRoot = ET.tostring(root, encoding=&#39;UTF-8&#39;, method=&#39;xml&#39;)
        tpf.write(stringRoot)

        inv = obspy.read_inventory(tpf.name, format=&#39;STATIONXML&#39;, level=&#39;response&#39;)
        tpf.close()

        os.remove(tpf.name)
    params[&#39;inv&#39;] = inv
    return params</code></pre>
</details>
</dd>
<dt id="sprit.warning"><code class="name flex">
<span>def <span class="ident">warning</span></span>(<span>sender, warn_message)</span>
</code></dt>
<dd>
<div class="desc"><p>Print a warning message</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def warning(sender, warn_message):
    &#34;&#34;&#34;Print a warning message&#34;&#34;&#34;
    print(&#34;[WARN] from %s: %s&#34; % (sender, warn_message), flush=True)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-submodules">Sub-modules</a></h3>
<ul>
<li><code><a title="sprit.sprit" href="sprit.html">sprit.sprit</a></code></li>
<li><code><a title="sprit.sprit_gui" href="sprit_gui.html">sprit.sprit_gui</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="sprit.check_mark" href="#sprit.check_mark">check_mark</a></code></li>
<li><code><a title="sprit.check_peaks" href="#sprit.check_peaks">check_peaks</a></code></li>
<li><code><a title="sprit.checkifpath" href="#sprit.checkifpath">checkifpath</a></code></li>
<li><code><a title="sprit.error" href="#sprit.error">error</a></code></li>
<li><code><a title="sprit.fetch_data" href="#sprit.fetch_data">fetch_data</a></code></li>
<li><code><a title="sprit.generate_ppsds" href="#sprit.generate_ppsds">generate_ppsds</a></code></li>
<li><code><a title="sprit.get_char" href="#sprit.get_char">get_char</a></code></li>
<li><code><a title="sprit.get_metadata" href="#sprit.get_metadata">get_metadata</a></code></li>
<li><code><a title="sprit.gui" href="#sprit.gui">gui</a></code></li>
<li><code><a title="sprit.hvplot" href="#sprit.hvplot">hvplot</a></code></li>
<li><code><a title="sprit.info" href="#sprit.info">info</a></code></li>
<li><code><a title="sprit.input_params" href="#sprit.input_params">input_params</a></code></li>
<li><code><a title="sprit.message" href="#sprit.message">message</a></code></li>
<li><code><a title="sprit.plot_hvsr" href="#sprit.plot_hvsr">plot_hvsr</a></code></li>
<li><code><a title="sprit.plot_specgram_hvsr" href="#sprit.plot_specgram_hvsr">plot_specgram_hvsr</a></code></li>
<li><code><a title="sprit.plot_specgram_stream" href="#sprit.plot_specgram_stream">plot_specgram_stream</a></code></li>
<li><code><a title="sprit.plot_stream" href="#sprit.plot_stream">plot_stream</a></code></li>
<li><code><a title="sprit.print_report" href="#sprit.print_report">print_report</a></code></li>
<li><code><a title="sprit.process_hvsr" href="#sprit.process_hvsr">process_hvsr</a></code></li>
<li><code><a title="sprit.remove_noise" href="#sprit.remove_noise">remove_noise</a></code></li>
<li><code><a title="sprit.select_windows" href="#sprit.select_windows">select_windows</a></code></li>
<li><code><a title="sprit.setup_colab" href="#sprit.setup_colab">setup_colab</a></code></li>
<li><code><a title="sprit.show_removed_windows" href="#sprit.show_removed_windows">show_removed_windows</a></code></li>
<li><code><a title="sprit.time_it" href="#sprit.time_it">time_it</a></code></li>
<li><code><a title="sprit.trim_data" href="#sprit.trim_data">trim_data</a></code></li>
<li><code><a title="sprit.update_shake_metadata" href="#sprit.update_shake_metadata">update_shake_metadata</a></code></li>
<li><code><a title="sprit.warning" href="#sprit.warning">warning</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>